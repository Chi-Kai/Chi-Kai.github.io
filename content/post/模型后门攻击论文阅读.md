---
author: KC
type: post
tags:
  - 论文阅读
date: 2024-09-19
description: 
toc: true
draft: false
---
# CCS'24 BadMerging: Backdoor Attacks Against Model Merging
## 摘要

随着预训练模型在下游任务中的广泛应用，模型融合（Model Merging, MM）作为一种有效的知识转移方法应运而生。MM通过合并多个独立微调的任务特定模型来构建一个能够处理多种任务的增强型模型。然而，这种方法可能引入安全风险，尤其是后门攻击。后门攻击允许攻击者通过在训练数据中注入恶意触发器来破坏机器学习模型。在本文中，我们首次提出了BadMerging，这是一种专门针对模型融合的后门攻击方法。BadMerging通过两阶段攻击机制和一种新颖的特征插值损失函数，即使在合并参数变化时，也能增强嵌入后门的鲁棒性。我们的方法不仅能够对攻击者提供的任务（on-task attack）进行攻击，还能对其他贡献者提供的任务（off-task attack）进行攻击。广泛的实验表明，BadMerging对各种模型融合算法都具有显著的攻击效果，并且现有的防御机制无法有效防御我们的攻击，这突显了需要更高级防御机制的必要性。

## 背景

模型融合（MM）是一种新兴的技术，它通过合并多个微调后的任务特定模型来提高模型在多个任务上的性能。这种方法的优势在于能够利用已有的模型和知识，减少存储成本和计算资源，同时提高模型的通用性和性能。然而，这种合并过程也带来了安全隐患。如果合并的模型中包含了被恶意修改的模型，那么整个合并后的模型可能会继承这些安全漏洞，从而受到攻击者的控制。尽管模型融合的实用性已经得到了广泛认可，但其安全性问题却鲜有研究。

在本文中，我们关注的是模型融合中的后门攻击问题。后门攻击是一种常见的安全攻击手段，它通过在模型的训练过程中植入特定的触发器，使得模型在遇到带有这些触发器的输入时表现出异常行为。在模型融合的背景下，攻击者可能只需要提供一个包含后门的任务特定模型，就可以影响整个合并后的模型。这种攻击方式的挑战在于，攻击者无法控制合并过程中的参数设置，因此需要设计一种能够适应不同合并参数的攻击策略。

## 相关工作

在机器学习安全领域，后门攻击和模型融合是两个重要的研究方向。后门攻击的研究主要集中在如何通过数据污染或模型操纵来植入后门，以及如何检测和防御这些攻击。而模型融合的研究则集中在如何有效地合并多个模型以提高性能和知识转移。

现有的后门攻击方法主要分为数据污染和模型污染两大类。数据污染方法通过在训练数据中注入带有触发器的样本来植入后门，而模型污染方法则通过修改模型的训练过程或结构来实现。这些方法在单一任务模型上取得了一定的成功，但在模型融合的背景下，由于缺乏对合并过程的控制，它们的有效性受到了限制。

模型融合的研究则涉及到如何合并来自不同任务或领域的模型，以及如何通过合并来提高模型的性能和泛化能力。这些研究通常假设合并的模型是安全的，而没有考虑到潜在的安全风险。

## 方案设计

BadMerging攻击框架包含两个主要部分：攻击机制设计和特征插值损失函数。

1. **两阶段攻击机制**：BadMerging首先在第一阶段生成一个通用触发器，该触发器能够在合并参数为0时激活后门。然后在第二阶段，攻击者使用这个触发器来微调其任务特定模型，确保在合并参数为1时攻击有效。这样，攻击在合并参数从0到1的任何值下都能保持有效。

2. **特征插值损失函数**：为了增强触发器在不同合并参数下的鲁棒性，我们提出了一种新颖的特征插值损失函数。该损失函数通过插值触发器图像的特征，强制模型在不同合并参数下都将触发器图像分类为目标类别。

## 实验结果

我们的实验设计包括了多种模型融合算法，以及与现有后门攻击方法的比较。实验结果表明：

1. **攻击效果**：BadMerging在多种模型融合算法下都能实现高达90%以上的攻击成功率，显著优于现有方法。

2. **防御机制评估**：我们评估了现有的检测和防御机制，包括Neural Cleanse和Fine-pruning，结果表明这些机制无法有效防御BadMerging攻击。

## 自己思考

**优点**：
- BadMerging是首个针对模型融合的后门攻击框架，填补了该领域的研究空白。
- 通过两阶段攻击机制和特征插值损失函数，BadMerging展示了对不同合并参数的鲁棒性。

**缺点**：
- BadMerging需要对攻击者的任务特定模型进行微调，这可能需要较大的计算资源。
- 论文中没有详细讨论攻击在不同规模和复杂度的模型上的效果。

**未来改进的方向**：
- 探索在更大规模的数据集和模型上的攻击效果，以及如何优化攻击策略以减少资源消耗。
- 研究如何结合多种防御机制来提高模型融合的安全性。
- 考虑实际部署场景，研究如何在不牺牲太多性能的情况下提高模型的鲁棒性。

# CCS'24 Neural Dehydration: Effective Erasure of Black-box Watermarks from DNNs with Limited Data 
## 摘要

本文提出了一种名为“Neural Dehydration”（简称Dehydra）的新型攻击框架，旨在有效移除深度神经网络（DNN）中的黑盒水印。黑盒水印是一种保护DNN知识产权的技术，通过在特定样本集上嵌入水印信息，并在疑似模型中提取水印以验证所有权。现有的水印移除攻击通常需要大量数据或对水印结构有先验知识，但这些攻击往往只能破解一小部分主流黑盒水印，且可能损害模型效用或依赖于大量数据。Dehydra通过利用DNN的内部结构来恢复和忘却水印信息，有效移除了所有十种主流黑盒水印，且只需有限或甚至不需要数据。具体来说，Dehydra首先使用模型反演技术恢复接近真实水印数据的样本，然后在微调过程中故意忘却这些样本。此外，Dehydra还引入了目标类别检测和恢复样本分割算法，以减少效用损失并实现无数据水印移除。在三个基准数据集和DNN架构上的广泛评估表明，Dehydra在数据有限的设置下，至少保留了90%的模型效用，同时实现了对所有覆盖水印的强效移除效果。

## 背景

随着深度学习技术的快速发展，训练一个高性能的DNN模型变得越来越重要。然而，模型训练需要大量的数据收集和计算资源。为了保护这些训练好的模型不被非法复制或滥用，模型水印技术应运而生。水印技术通过在模型训练过程中嵌入特定的信息，使得在模型被非法使用时能够追踪到原始所有者。黑盒水印因其验证过程只需API访问而受到广泛关注。然而，现有的水印技术面临着被攻击者移除的风险，攻击者可能会通过修改模型参数来使水印失效。尽管已有研究提出了多种水印移除攻击，但这些攻击往往需要大量数据或对水印结构有深入了解，这在实际场景中是不现实的。因此，本文提出了一种无需数据或只需有限数据的水印移除攻击方法，旨在提高攻击的实用性和有效性。

## 相关工作

在DNN模型水印领域，已有多种水印嵌入和提取技术被提出。这些技术主要分为白盒水印和黑盒水印两大类。白盒水印需要对模型内部参数进行访问，而黑盒水印则只需通过模型的预测行为进行验证。此外，针对水印的安全性，研究者们还提出了多种攻击方法，包括基于剪枝、微调和反学习的攻击。这些攻击方法试图通过修改模型参数或训练数据来移除水印，但它们通常需要大量数据或对水印算法有先验知识。最近，一些研究开始关注在数据受限条件下的水印移除问题，提出了一些新的攻击策略。然而，这些方法在实际应用中仍存在局限性，如攻击效果不佳或对数据的依赖性仍然较高。本文提出的Dehydra方法正是为了解决这些问题，通过利用模型内部信息来实现有效的水印移除，同时减少对外部数据的依赖。

## 方案设计

Dehydra攻击框架主要包含两个阶段：水印恢复和水印忘却。在水印恢复阶段，Dehydra使用模型反演技术从目标水印模型中恢复出接近真实水印数据的样本。这一阶段利用了DNN的过参数化特性，通过优化技术重建与目标类别相关联的水印信息。在水印忘却阶段，Dehydra在微调过程中故意忘却这些恢复出的样本，以此来移除水印。为了提高攻击的有效性和减少对数据的依赖，Dehydra进一步引入了目标类别检测和恢复样本分割算法。目标类别检测算法通过分析模型的损失景观来识别固定类别的水印，并检测其目标类别。恢复样本分割算法则基于正常数据优势现象，将恢复样本分割为代理水印数据和代理正常数据，以确保在移除水印的同时保持模型的原始效用。Dehydra的这些设计使其能够在数据受限的条件下实现有效的水印移除。

## 实验结果

实验部分首先介绍了实验的设计，包括使用的数据集、DNN架构、水印算法和攻击方法。作为基线的攻击方法包括剪枝、微调和反学习等。实验结果表明，Dehydra在数据有限的设置下，能够实现对所有十种主流黑盒水印的强效移除，同时至少保留了90%的模型效用。与现有攻击方法相比，Dehydra在移除水印方面表现出更高的有效性，且对模型效用的影响更小。

## 自己思考

本文提出的Dehydra方法在水印移除领域具有创新性，特别是在减少对数据依赖和提高攻击有效性方面。然而，该方法也有一些局限性。首先，Dehydra主要针对图像分类任务，对于其他类型的DNN模型，如自然语言处理模型，其有效性尚未得到验证。其次，Dehydra的攻击效果可能受到模型结构和水印算法设计的影响，对于某些特定的水印算法，可能需要进一步调整攻击策略。未来的工作可以探索Dehydra在其他任务和模型上的应用，并研究如何提高其对不同水印算法的适应性。此外，研究者们还可以探索如何结合Dehydra与其他攻击方法，以实现更全面的水印防御策略。
