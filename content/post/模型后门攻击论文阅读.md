---
author: KC
type: post
tags:
  - 论文阅读
date: 2024-09-19
description: 
toc: true
draft: false
---
## 摘要

随着预训练模型在下游任务中的广泛应用，模型融合（Model Merging, MM）作为一种有效的知识转移方法应运而生。MM通过合并多个独立微调的任务特定模型来构建一个能够处理多种任务的增强型模型。然而，这种方法可能引入安全风险，尤其是后门攻击。后门攻击允许攻击者通过在训练数据中注入恶意触发器来破坏机器学习模型。在本文中，我们首次提出了BadMerging，这是一种专门针对模型融合的后门攻击方法。BadMerging通过两阶段攻击机制和一种新颖的特征插值损失函数，即使在合并参数变化时，也能增强嵌入后门的鲁棒性。我们的方法不仅能够对攻击者提供的任务（on-task attack）进行攻击，还能对其他贡献者提供的任务（off-task attack）进行攻击。广泛的实验表明，BadMerging对各种模型融合算法都具有显著的攻击效果，并且现有的防御机制无法有效防御我们的攻击，这突显了需要更高级防御机制的必要性。

## 背景

模型融合（MM）是一种新兴的技术，它通过合并多个微调后的任务特定模型来提高模型在多个任务上的性能。这种方法的优势在于能够利用已有的模型和知识，减少存储成本和计算资源，同时提高模型的通用性和性能。然而，这种合并过程也带来了安全隐患。如果合并的模型中包含了被恶意修改的模型，那么整个合并后的模型可能会继承这些安全漏洞，从而受到攻击者的控制。尽管模型融合的实用性已经得到了广泛认可，但其安全性问题却鲜有研究。

在本文中，我们关注的是模型融合中的后门攻击问题。后门攻击是一种常见的安全攻击手段，它通过在模型的训练过程中植入特定的触发器，使得模型在遇到带有这些触发器的输入时表现出异常行为。在模型融合的背景下，攻击者可能只需要提供一个包含后门的任务特定模型，就可以影响整个合并后的模型。这种攻击方式的挑战在于，攻击者无法控制合并过程中的参数设置，因此需要设计一种能够适应不同合并参数的攻击策略。

## 相关工作

在机器学习安全领域，后门攻击和模型融合是两个重要的研究方向。后门攻击的研究主要集中在如何通过数据污染或模型操纵来植入后门，以及如何检测和防御这些攻击。而模型融合的研究则集中在如何有效地合并多个模型以提高性能和知识转移。

现有的后门攻击方法主要分为数据污染和模型污染两大类。数据污染方法通过在训练数据中注入带有触发器的样本来植入后门，而模型污染方法则通过修改模型的训练过程或结构来实现。这些方法在单一任务模型上取得了一定的成功，但在模型融合的背景下，由于缺乏对合并过程的控制，它们的有效性受到了限制。

模型融合的研究则涉及到如何合并来自不同任务或领域的模型，以及如何通过合并来提高模型的性能和泛化能力。这些研究通常假设合并的模型是安全的，而没有考虑到潜在的安全风险。

## 方案设计

BadMerging攻击框架包含两个主要部分：攻击机制设计和特征插值损失函数。

1. **两阶段攻击机制**：BadMerging首先在第一阶段生成一个通用触发器，该触发器能够在合并参数为0时激活后门。然后在第二阶段，攻击者使用这个触发器来微调其任务特定模型，确保在合并参数为1时攻击有效。这样，攻击在合并参数从0到1的任何值下都能保持有效。

2. **特征插值损失函数**：为了增强触发器在不同合并参数下的鲁棒性，我们提出了一种新颖的特征插值损失函数。该损失函数通过插值触发器图像的特征，强制模型在不同合并参数下都将触发器图像分类为目标类别。

## 实验结果

我们的实验设计包括了多种模型融合算法，以及与现有后门攻击方法的比较。实验结果表明：

1. **攻击效果**：BadMerging在多种模型融合算法下都能实现高达90%以上的攻击成功率，显著优于现有方法。

2. **防御机制评估**：我们评估了现有的检测和防御机制，包括Neural Cleanse和Fine-pruning，结果表明这些机制无法有效防御BadMerging攻击。

## 自己思考

**优点**：
- BadMerging是首个针对模型融合的后门攻击框架，填补了该领域的研究空白。
- 通过两阶段攻击机制和特征插值损失函数，BadMerging展示了对不同合并参数的鲁棒性。

**缺点**：
- BadMerging需要对攻击者的任务特定模型进行微调，这可能需要较大的计算资源。
- 论文中没有详细讨论攻击在不同规模和复杂度的模型上的效果。

**未来改进的方向**：
- 探索在更大规模的数据集和模型上的攻击效果，以及如何优化攻击策略以减少资源消耗。
- 研究如何结合多种防御机制来提高模型融合的安全性。
- 考虑实际部署场景，研究如何在不牺牲太多性能的情况下提高模型的鲁棒性。
