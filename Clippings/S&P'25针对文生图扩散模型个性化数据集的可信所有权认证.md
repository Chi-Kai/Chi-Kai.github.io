---
title: S&P'25|针对文生图扩散模型个性化数据集的可信所有权认证
source: https://zhuanlan.zhihu.com/p/13930676207?utm_medium=social&utm_psn=1854650946996559873&utm_source=wechat_session&utm_id=0&s_r=0
author: []
published: 
created: 2025-01-07
description: 很荣幸我们的近期工作 Towards Reliable Verification of Unauthorized Data Usage in Personalized Text-to-Image Diffusion Models被安全四大会议之首的IEEE S&amp;P 2025接收! 本文是我们数据集所有权认证 (Dat…
tags:
---
很荣幸我们的近期工作[Towards Reliable Verification of Unauthorized Data Usage in Personalized Text-to-Image Diffusion Models](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2410.10437)被安全四大会议之首的IEEE S&P 2025接收!

本文是我们[数据集](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E6%95%B0%E6%8D%AE%E9%9B%86&zhida_source=entity)所有权认证 (Dataset Ownership Verification) 任务开坑以来的第四篇工作，在该工作中我们**揭示了现有针对T2I[扩散模型](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B&zhida_source=entity)数据集水印的内在缺陷**，**提出了首个有效、可信赖的水印和基于此的数据集所有权认证**，**助力保护包括艺术作品在内的T2I扩散模型个性化/风格化数据集的[版权](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E7%89%88%E6%9D%83&zhida_source=entity)**。当然，这也是我们在GenAI场景下的第一篇数据集所有权认证工作，这进一步揭示了这一任务的普适性和重要性。

有趣的是，我们在数据集所有权认证领域中的所有工作似乎都是一投就中，希望这种[一发入魂](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E4%B8%80%E5%8F%91%E5%85%A5%E9%AD%82&zhida_source=entity)的好运常在。特别的，我们开发的数据集所有权认证方法目前也成为了数据集版权审计中两大最主流的技术之一（更多细节见[IEEE S&P'25 SoK](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2410.16618)）。相比于基于指纹或成员推理的另一主流数据集版权审计技术，数据集所有权认证技术通过植入外源特征的方式，在保证认证准确率的前提下极大的降低了假阳误判的概率。**欢迎各位小伙伴们来和我们一起继续深挖数据集所有权认证这一新兴但重要的领域**！

**PS:** 前三篇工作（[TIFS'23](https://link.zhihu.com/?target=https%3A//ieeexplore.ieee.org/abstract/document/10097580)、[NeurIPS‘22](https://link.zhihu.com/?target=https%3A//www.researchgate.net/publication/363766436_Untargeted_Backdoor_Watermark_Towards_Harmless_and_Stealthy_Dataset_Copyright_Protection)、[NeurIPS'23](https://link.zhihu.com/?target=https%3A//www.researchgate.net/publication/374440504_Domain_Watermark_Effective_and_Harmless_Dataset_Copyright_Protection_is_Closed_at_Hand)）的导读见我们之前的[知乎介绍](https://zhuanlan.zhihu.com/p/591166261)、[清华新闻](https://link.zhihu.com/?target=https%3A//www.tsinghua.edu.cn/info/1175/104618.htm)、[知乎介绍](https://zhuanlan.zhihu.com/p/659553493/)，也欢迎大家关注我们最近的[IEEE SPS Webinar](https://link.zhihu.com/?target=https%3A//rc.signalprocessingsociety.org/education/webinars/spsweb24031)。

## 一、背景

高质量的公开数据集（例如开源数据集或正在售卖的商业数据集）是深度学习繁荣的一个重要因素。然而，由于这些数据集的公开特性，**恶意用户很有可能在未经授权的情况下用其训练第三方商用模型，进而破坏数据集所有者的版权**，给数据集的所有者造成巨大的损失。

特别的，在[生成式人工智能](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&zhida_source=entity)，尤其是文生图场景中，**恶意用户/[开发者](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E5%BC%80%E5%8F%91%E8%80%85&zhida_source=entity)可能会在未经授权的情况下，利用艺术家等受害者的图像数据集对T2I扩散模型进行个性化调整（例如微调），从而侵犯受害者的版权**。这个场景的具体过程如下图所示（该图来源于Glaze论文中）：

![](https://pic1.zhimg.com/v2-baf96e3556342b5614b6b9412042da6e_1440w.jpg)

Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models. USENIX Security, 2023.

目前，**数据集所有权认证（Dataset Ownership Verification，DOV）是保护这类开源数据集 (Public Dataset)最主流和有效的方法**。简单来说，在该方法中，**数据集的所有者会在发布数据集之前对其添加特殊的水印，使得所有在该数据集上训练/微调过的模型都会（在特定的样本上）有特殊的预测行为**。如果可疑模型中存在这一特定预测行为，则该模型可以被认为是在受保护的数据集上训练过。

![](https://pic1.zhimg.com/v2-7f9092b301712098a65dc659a411d5a4_1440w.jpg)

在本文中，我们讨论如何通过DOV保护文生图扩散模型个性化数据集的版权。

## 二、重新审视现有针对T2I的水印方法

目前针对T2I个性化数据集的所有权认证分为两大基础类型：基于[图像水印](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E5%9B%BE%E5%83%8F%E6%B0%B4%E5%8D%B0&zhida_source=entity)的方法（Watermark-based Methods）和基于后门水印的方法（Backdoor-based Methods）。在这个部分中，我们分别讨论其内在缺陷。

### 2.1 重新审视基于图像水印的方法

顾名思义，这类方法**旨在在受保护的图像中嵌入预定义的隐写信息，希望同样的信息能从个性化 T2I 模型生成的图像中解码出来**。

![](https://picx.zhimg.com/v2-496f3c46628c254fa89285edb7b8c0ed_1440w.jpg)

然而，如上图所示，我们发现：在使用最先进的扩散模型进行个性化学习时，**现有方法产生的水印很难被学习和保存**。我们认为，其中一个根本原因是：这些扩散模型已经在大型高质量文本-图像数据集上进行了预训练，从而在文本和图像概念之间建立了稳健的语义联系。换句话说，这些模型已经熟悉了一般概念，在遇到新概念时可能知道 “要学什么”。例如，预训练的扩散模型已经熟悉了狗的一般外观。当适应一种特定类型的新狗时，模型可能会主要关注这种新狗的独特细节，如毛发、眼睛和耳朵。然而，**这些方法的图像水印与待学习概念的语义联系有限，因此，模型可能会将其视为与图像背景类似的无关特征，从而在训练过程中将其忽略不计**。

### 2.2 重新审视基于后门水印的方法

目前，也有一个针对T2I模型的后门水印方案（即，DIAGNOSIS ）。具体的，**该方法在受保护的图像上添加隐蔽的后门触发器进行水印，并在相应的原始提示中附加触发文本**。因此，如果一个模型在这个数据集上进行训练，它就会学习一个 “后门”（即触发文本符合要求，就在生成的图像上添加相同的后门触发器）。**数据集的所有者只需要在生成时使用触发器文本，判断该可疑模型生成的图片中是否含有触发器图案，即可进行所有权认证**。

然而，**这个方法依赖了一个潜在的假设， 即：侵犯方使用的训练提示必须是数据集所有者提供的提示**。然而，攻击者可以使用目前最先进的图像标注模型（如 BLIP）生成高质量的文本描述作为训练提示，轻松绕过这一假设。此时，如下表所示，该方法会完全失效，因为**后门触发器的特征也和模型在个性化学习过程中想要学习的特征无关，从而在个性化学习过程中被模型忽略**。

![](https://pica.zhimg.com/v2-512da144856b1410e525d8106ad3a0b4_1440w.jpg)

## 三、所提方法（SIREN）

根据上述分析，我们认为：**现有方法失败源自于其可学性不足，因为它们的水印与个性化学习任务无关**。因此，**我们需要优化水印的生成过程，使其耦合于（Align with）个性化任务相关的特征**（Personalization-related Features）。通过这种方式，我们可以鼓励模型在个性化的过程中去学习水印，因此我们也将我们的方法命名为[SIREN](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Siren_%28mythology%29)（i.e., 古希腊神话中通过唱歌引诱水手的女妖）。

### 3.1 威胁模型

和现有的所有数据集所有权认证工作相同，我们假设**数据集的所有者只能通过API的形式黑盒的访问可疑模型，且不知道模型的任何训练信息和参数**。数据的所有者出于某些目的（如艺术品广告或促进学术研究）向公众发布其拥有的图像，即被保护的数据集具有公开特性（Public Characteristic）。然而，所有者不希望自己的数据在未经授权的情况下被用于商业目的，即我们所考虑的以盈利为目的的个性化扩散模型的训练和销售。

### 3.2 方法概述

总的来说，如下图所示，我们的方法包括两个阶段：（1）水印的构建和提取 以及 （2）基于水印的数据集所有权认证。在第一阶段中，防御者旨在**学习一个水印[生成器](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E7%94%9F%E6%88%90%E5%99%A8&zhida_source=entity)** $\mathcal{G} : \left(\mathbb{R}\right)^{c \times h \times w} \rightarrow \left(\mathbb{R}\right)^{c \times h \times w}$\\mathcal{G}: \\mathbb{R}^{c\\times h\\times w}\\rightarrow\\mathbb{R}^{c\\times h\\times w} **和一个水印[特征提取器](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%99%A8&zhida_source=entity)** $\Phi : \left(\mathbb{R}\right)^{c \times h \times w} \rightarrow \left(\mathbb{R}\right)^{d}$\\Phi:\\mathbb{R}^{c\\times h \\times w}\\rightarrow \\mathbb{R}^{d} 。在第二阶段，防御者**根据学习到的水印特征提取器，计算可疑模型和良性扩散模型在（个性化）生成图片上的分数，并进行比较**。

![](https://pic3.zhimg.com/v2-913990bd34756b1abbb9dbe763cb7c6e_1440w.jpg)

PS: 为了和图像水印区分，我们在论文中将生成式模型的数据集水印称为coating（而不是watermarking）

### 3.3 水印的构建和提取 (Training & Coating Stage)

**（1）学习性损失**（Learnability Loss）**：**为了确保水印的可学习性，我们设计了一个学习性损失。在介绍我们的损失设计之前，我们先定义一下什么叫和个性化特征有关的水印/涂层：

![](https://pic4.zhimg.com/v2-a922a6d3f9e61db6441b5aae0c438dc3_1440w.jpg)

简单的来说，上述定义表明：**如果水印与个性化相关的特征一致，则添加水印应能减少模型上文字-图像对的损失**。基于这种想法，我们设计了如下学习性损失（本质上就是上面两个loss相减）：

![](https://pic2.zhimg.com/v2-4c51faa58bc4da9af0a29d4c08daca17_1440w.jpg)

（2）**[感知损失](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E6%84%9F%E7%9F%A5%E6%8D%9F%E5%A4%B1&zhida_source=entity)**（Perceptual Loss）：为了确保水印的隐蔽性，我们需要让含有水印的图片看起来和以前的图片相似。受到近期人类[视觉感知系统](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5%E7%B3%BB%E7%BB%9F&zhida_source=entity)相关工作的启发， 我们将该损失定义如下：

![](https://pic3.zhimg.com/v2-497b04e9c4ee2d65971f4f25e13eccea_1440w.jpg)

![](https://pic1.zhimg.com/v2-8a9e1188de16ad12f782822aacef2352_1440w.jpg)

（3）**超球面分类损失（**Hypersphere Classification Loss**）**：至此，我们已经得到了使水印隐蔽且可学习的技术。我们的下一个目标是检测生成的个性化图片上是否存在水印。此时，**一个最直接的解决方案是使用标准的交叉熵损失对水印后的和水印前的干净图像直接训练[二元分类器](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E4%BA%8C%E5%85%83%E5%88%86%E7%B1%BB%E5%99%A8&zhida_source=entity)**，即在分类器的特征空间中学习一个超平面，以区分正样本（水印样本）和负样本（干净样本）。然而，**这种方法效果非常有限**，因为在现实世界中我们无法收集所有可能的干净图像是。因此，学习到的超平面可能会偏向于训练数据集，并可能导致对未见过的负数据进行错误分类，如下图（左半部分）所示：

![](https://pic3.zhimg.com/v2-59d415538dc9673e80888fbe8a3bdb90_1440w.jpg)

受之前相关工作的启发，**我们拟学习一个[超球面](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=2&q=%E8%B6%85%E7%90%83%E9%9D%A2&zhida_source=entity)而非一个超平面**，**该方法可以学习一个最小超球，它可以包含所有正样本，并将超球之外的所有其他样本视为负样本**。因此，学习到的边界将主要集中在正样本上（即，带有水印的图像），因此受负训练样本分布的影响较小，从而为未见过的负样本提供更好的泛化能力，如上图（右半部分）所示。此时，超球面分类损失的定义如下：

![](https://pic4.zhimg.com/v2-0f163a9b8086bb15d211dc7f8abc1c23_1440w.jpg)

综上所述，我们最终的损失函数如下所示：

![](https://pic3.zhimg.com/v2-94851a161abe25c38f1b9f10be71fa2a_1440w.jpg)

### 3.4 基于水印的数据集所有权认证 (Verification Stage)

给定一个由可疑模型生成的个性化图像 $x_{s}$x\_s ，我们可以通过将其投影到 $\Phi$\\Phi 对应的特征空间来确定它是否包含水印。具体的，我们会计算该图像到超球中心的距离 $s \left(\right. x_{s} \left.\right) = \parallel \Phi \left(\right. x_{s} \left.\right) - o \parallel_{2}^{2}$s(x\_s)=\\|\\Phi(x\_s)-o\\|\_2^2 ，我们称之为涂层得分（Coating Score）。**理想情况下，侵权模型生成的个性化图片对应的涂层分数较小，而良性模型对应的涂层分数较大**。

因此，我们可以通过 Kolmogorov-Smirnov 假设检验，验证可疑模型的涂层得分是否明显大于独立模型的涂层得分。**如果原假设被拒绝，则认为该可疑模型利用过被保护的数据集进行个性化训练**，具体如下所示**：**

![](https://pic1.zhimg.com/v2-1aaa12af98d9f78df126d8b257ace520_1440w.jpg)

PS：我们用K-S检验是因为它是一种[非参数检验](https://zhida.zhihu.com/search?content_id=251809056&content_type=Article&match_order=1&q=%E9%9D%9E%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C&zhida_source=entity)，不依赖于对两种分布的任何额外假设。因为涂层分数不一定符合高斯分布，因此不一定满足常用假设检验（例如t-检验）的前提。

## 四、实验结果

首先，我们在微调和更高级的个性化方法（例如DreamBooth）下都验证了我们方法的有效性：

![](https://pica.zhimg.com/v2-230e9476862ea05fdfafb5992ddf7834_1440w.jpg)

其次，我们也证实了我们方法具有可迁移性，因此是一种实用的方法：

![](https://pic1.zhimg.com/v2-49df34253fa266817ac31f05a801c8f6_1440w.jpg)

此外，我们的方法对生成图片的质量影响较小：

![](https://pic4.zhimg.com/v2-3fc6b2f93bb5eac4171f420ff55d79fd_1440w.jpg)

最后，我们也讨论了潜在攻击方法（例如基于损失值的过滤和遗忘学习，ABL）的抵御效果：

![](https://pica.zhimg.com/v2-8181280040d5b30ec099513effa3d38a_1440w.jpg)

PS: 更多的实验结果和细节请参考我们的原论文 :)

