<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>联邦学习 on 悉达多</title><link>https://chi-kai.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/</link><description>Recent content in 联邦学习 on 悉达多</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Wed, 15 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://chi-kai.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://chi-kai.github.io/post/%E6%B0%B4%E5%8D%B0%E9%AA%8C%E8%AF%81/</link><pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate><guid>https://chi-kai.github.io/post/%E6%B0%B4%E5%8D%B0%E9%AA%8C%E8%AF%81/</guid><description>&lt;h2 id="后门水印">后门水印&lt;/h2>
&lt;ol>
&lt;li>服务器嵌入 2 客户端验证（客户端能力弱，不能嵌入）&lt;/li>
&lt;li>如何客户端保证收到的服务器模型。&lt;/li>
&lt;li>嵌入服务器调度?&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>联邦学习论文阅读</title><link>https://chi-kai.github.io/post/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link><pubDate>Sun, 06 Nov 2022 00:00:00 +0000</pubDate><guid>https://chi-kai.github.io/post/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</guid><description>&lt;h2 id="towards-on-device-federated-learning-a-direct-acyclic-graph-based-blockchain-approach">《Towards On-Device Federated Learning: A Direct Acyclic Graph-based Blockchain Approach》&lt;/h2>
&lt;h3 id="目标">目标&lt;/h3>
&lt;p>为了解决联邦学习中的设备异步和异常检测问题，同时避免由区块链导致的资源浪费&lt;/p>
&lt;ul>
&lt;li>
&lt;p>设备异步。传统的中心化和同步FL(Google FL),一个节点必须等待其他节点完成任务才能一起进入下一轮训练，一个崩溃的节点可能阻塞整个系统。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>异常检测。一个节点的数据集和操作对其他节点是不可见的。一些恶意节点可能会破坏整个系统的准确度和降低效率。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="主要贡献">主要贡献&lt;/h3>
&lt;p>提出了第一个基于DAG的FL异步框架来解决设备异步和异常节点检测问题。&lt;/p>
&lt;h3 id="dag-fl-模型">DAG-FL 模型&lt;/h3>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7vnbi5q76j30ru0n1tcw.jpg" alt="DAG-FL结构.png">&lt;/p>
&lt;p>“This feature promises that a node in DAG-FL can immediately participate in an iteration of FL whenever it is in idle state. When the node completes an iteration of FL and gets a new trained local model, the new local model can be published on its local DAG as a transaction immediately, and latter the new published transaction would be seen by all other nodes.” (&lt;a href="zotero://select/library/items/MG76RNTD">Cao 等。, p. 4&lt;/a>) (&lt;a href="zotero://open-pdf/library/items/BZ4CNUBL?page=4">pdf&lt;/a>) ”&lt;/p>
&lt;p>还是用本地的数据来训练模型，并没有和其他节点做聚合？&lt;/p>
&lt;p>“initial” (&lt;a href="zotero://select/library/items/MG76RNTD">Cao 等。, p. 5&lt;/a>) (&lt;a href="zotero://open-pdf/library/items/BZ4CNUBL?page=5">pdf&lt;/a>)&lt;/p>
&lt;h3 id="异步构架">异步构架&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>FL Layer:&lt;/p>
&lt;p>全局模型由存储在DAG中的本地模型使用FedAvg算法聚合产生，节点使用本地数据集进行训练。得到的新的模型被当作一个交易发布到DAG中。（每笔交易就是一个模型）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DAG Layer:&lt;/p>
&lt;p>每个节点维护一个本地DAG，其中每个交易包含下相应的认证信息，本地模型参数，和许可链接。本地DAG通过广播和无线网络更新，最终一个新的交易可以得到传播。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Application Layer:&lt;/p>
&lt;p>一个外部接口，通过智能合约发布任务。这个客户端可以观察整个FL过程的进展，从而控制整个FL的进行和停止。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>异步性分析：&lt;/p>
&lt;p>   在整个DAG-FL中没有central server,每个节点是通过本地已有的模型来构建新的全局模型。节点可以在合适的时间来进行FL迭代，获取的新的模型发布在本地DAG,随后可以被其他节点所见。节点之间的行为互不影响可以异步进行。&lt;/p>
&lt;h3 id="共识算法">共识算法&lt;/h3>
&lt;p>当一个节点完成一轮迭代，生成一个新的模型。他会从本地DAG选取几个tips(加入DAG但是没有被验证的block)来进行验证:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>验证使用RSA等算法加密的身份证书。可以避免恶意节点的女巫攻击。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用本地的测试集来计算模型的精确度。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>然后选取模型精确度最高的几个模型来构成新的全局模型。&lt;/p>
&lt;p>节点使用这个模型和本地数据集训练，得到的新模型通过一个新的交易发布到DAG中。&lt;/p>
&lt;p>随着DAG的持续扩展，一个交易的每次认证都意味着这个交易代表的模型被选择去构建一个全局模型，进而影响最终模型的生成。得到的认证越多，它在FL中的影响越大。反之，节点就会被孤立，在FL中影响越小。&lt;/p>
&lt;p>所以，最终DAG-FL训练的模型会向大多数节点期望的方向发展，少部分恶意节点会逐渐被孤立，影响降到最小化。&lt;/p>
&lt;h3 id="fl算法">FL算法&lt;/h3>
&lt;p>符号定义:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>D = {1,2,3,…,N $_D$ },代表整个设备集群。D $_i$是第i个节点。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>S $_i$是D $_i$的训练集，|S $_i$| = N $_i$,这里N $_i$是S $_i$的samples数量。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>D $_i$在本地创建一个仅自己可见的DAG为g $_i$，存储在其中的交易为w&lt;/p>
&lt;/li>
&lt;li>
&lt;p>时间t，在D $_i$训练得到的本地模型为w $_i$ $^t$&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>算法流程:&lt;/p>
&lt;ol>
&lt;li>D $_i$在t $_0$开始FL算法迭代，首先验证本地DAG的一些tips(验证他们的身份和用测试集验证准确度)&lt;/li>
&lt;li>将准确度较高的的k个tips使用FedAvg算法聚合成一个全局模型:
$$
\omega^{t_{0}}=\sum_{i=1}^{k} n_{i} \omega_{d_{i}}^{t_{i}}
$$
这里 n $_i$是表示模型重要性的权重因子，为了简化这里设置为1/k,表示同等重要。&lt;/li>
&lt;li>节点从数据集S $_i$中提取m个samples作为一个最小batch z$_i$ 来对得到的全局模型训练 $\beta$个epochs.&lt;/li>
&lt;li>得到一个新模型 $\omega &lt;em>{i}^{ t&lt;/em>{0}}$,将它发布到$g_{i}$上。&lt;/li>
&lt;/ol>
&lt;h3 id="dag-fl-操作">DAG-FL 操作&lt;/h3>
&lt;p>这里介绍框架中的两个重要算法。&lt;/p>
&lt;h4 id="dag-fl-controlling">DAG-FL Controlling&lt;/h4>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7voje2iexj30tp0r90zh.jpg" alt="DAG-FL Controlling.png">&lt;/p>
&lt;p>在应用层的外接客户端可以认为是一个权威组织，负责任务发布任务。通过智能合约执行DAG-FL 控制算法。过程如上图。&lt;/p>
&lt;h4 id="dag-fl-updating">DAG-FL Updating&lt;/h4>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7vro3iz6gj30tr0qu0ze.jpg" alt="DAG-FL Updating.png">&lt;/p>
&lt;p>节点在空闲时执行DAG-FL Updating 算法。&lt;/p>
&lt;ol>
&lt;li>节点随机从本地DAG选取staleness范围在可以接收的tip。&lt;/li>
&lt;li>节点先认证所选tips的身份，然后用自己的test数据集来计算所选tips的模型精确度。&lt;/li>
&lt;li>选择精确度高的k个tips，使用FedAvging算法得到一个全局模型。节点用本地数据来训练这个全局模型。&lt;/li>
&lt;li>一个新的交易被生成。包括身份信息，上一阶段训练得到的模型，和最k个tips的验证信息。&lt;/li>
&lt;/ol>
&lt;h3 id="未来工作">未来工作&lt;/h3>
&lt;ol>
&lt;li>在模型可用性上，使用一个小的test set可能对于一些特定场景不适合，考虑其他的异常检测方法。&lt;/li>
&lt;li>信用评估&lt;/li>
&lt;li>权重聚合。本文的模型使用的方法是同等权重系数的FedAvg,可以使用更好的方法来给高质量的模型更高的权重提高模型精度。&lt;/li>
&lt;/ol>
&lt;h2 id="implicit-model-specialization-through-dag-based-decentralized-federated-learning">《Implicit Model Specialization through DAG-based Decentralized Federated Learning》&lt;/h2>
&lt;h3 id="背景">背景&lt;/h3>
&lt;p>由于联邦学习数据的非独立同分布特性，所有节点训练一个模型太过宽泛，提出一种基于DAG区块链的联邦学习框架，所有节点利用本地数据和其他节点相似的数据训练自己的特例化模型，和全局的泛化模型结合来提高系统的性能。&lt;/p>
&lt;p>这篇论文是在联邦学习之前已经有的对本地数据特例化的研究基础上，引入DAG区块链。&lt;/p>
&lt;h3 id="模型">模型&lt;/h3>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/12/EWSmpuqlzK4TMAt.png" alt="">&lt;/p>
&lt;p>每个节点执行四个步骤，通过基础的随机移动算法选择DAG上的两个tips,将这个两个选择的模型参数平均，得到的模型在本地数据集上训练，如果最终得到的模型有提高就发布。&lt;/p>
&lt;h4 id="tips选择算法">tips选择算法&lt;/h4>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/12/clpHA9C21hkRoUV.png" alt="">
从区块链接的相反方向随机遍历。每个交易(区块)根据它的子图大小分配一个权重，通常会选择最高权重的区块，使得这个遍历方向收敛。
&lt;img src="https://s2.loli.net/2022/11/12/uJkGPclTq24VEDa.png" alt="">&lt;/p>
&lt;p>同时，对于每个节点有特定化的偏向处理，遍历的每一步，对于下一跳可以到达的潜在模型在本地数据集上进行评估。&lt;/p>
&lt;p>WEIGHTEDCHOICE 函数从这些模型中随机选择，并根据子节点对本地数据的精确度进行加权。（到底是按照权重还是随机选择？）&lt;/p>
&lt;p>这里的精确度计和权重计算：&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/12/NxPmWCyJBFhMAbv.png" alt="">&lt;/p>
&lt;p>遍历的随机性可以由 α 参数确定，其中值越大，权重之间的差异越大，因此随机性越小，确定性越高。另一方面，较小的 α 值会导致权重收敛，从而导致更多随机性。模型之间的预期精度差异取决于我们的方法所应用的机器学习问题，以及学习率、批量大小和局部时期等超参数。为了在模型之间的精度变化很小的情况下也能实现良好的特性化，即使在差异很大的情况下也能实现良好的泛化，将每个步骤中的精度分布 max(accuracies) - min(accuracies) 精度归一化 * 的一部分：&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/12/cHbGaDKXUvMLl6P.png" alt="">&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/12/7bDcLwGtZp2e1Co.png" alt="">&lt;/p>
&lt;h2 id="safa-a-semi-asynchronous-protocol-for-fast-federated-learning-with-low-overhead">《SAFA: A Semi-Asynchronous Protocol for Fast Federated Learning With Low Overhead》&lt;/h2>
&lt;h3 id="背景-1">背景&lt;/h3>
&lt;p>原有的FedAvg算法存在一些问题:&lt;/p>
&lt;ul>
&lt;li>同步开销大： 每轮迭代中央服务器需要传输全局模型给所有客户端，带宽达到一个峰值。&lt;/li>
&lt;li>客户端利用不足：随机选择的客户端使得许多可以参加训练的客户端闲置。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>这个论点不充分。FedAvg是在所有可用的客户端中随机选择一定比例，并不是完全随机的。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>进度浪费: 被选中的设备如果在完成本地训练之前失败，则之前的工作都会作废。&lt;/li>
&lt;li>每回合效率低: 在每轮结束进行聚合，FedAvg必须等待所有客户端完成。如果一些客户端故障，整个过程会等到超时结束。&lt;/li>
&lt;/ul>
&lt;h3 id="模型-1">模型&lt;/h3>
&lt;p>SAFA包括三部分: Lag-tolerant Model Distribution (&lt;strong>滞后容忍模型分布&lt;/strong>)，Compensatory
First-Come-First-Merge (CFCFM) client selection [&lt;strong>补偿性先到先合并 (CFCFM) 客户端选择&lt;/strong>],
discriminative aggregation (&lt;strong>判别聚合&lt;/strong>)&lt;/p>
&lt;p>下面SAFA的一个系统图:&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/13/R9dHQ6s1tjNDrWp.png" alt="">&lt;/p>
&lt;p>文中所用的参数表&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/13/wXgupKY9TJLVN3Z.png" alt="">&lt;/p>
&lt;h4 id="lag-tolerant-model-distribution">Lag-tolerant Model Distribution&lt;/h4>
&lt;p>整个模块关键的有两点:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>有选择的同步全局模型。&lt;/p>
&lt;p>不像FedAvg算法一样每轮每个参与节点都要同步模型，这是一个交流密集的过程，开销很大。SAFA模型只要求两种类型必须同步。&lt;strong>上一轮成功完成的节点(FedAvg中的正常节点)和被标记为过时的节点&lt;/strong>，这个过时节点是由于网络或者其他原因本地模型落后全局太多的客户端。这里有个滞后容忍参数 $\tau$，来调节这个滞后范围。&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/13/HYekTp8LqDa92Ic.png" alt="">&lt;/p>
&lt;p>这里t-1表示上一轮的最新模型, $\omega _{k}$代表第k个节点的本地模型，$\omega$ 代表全局模型。可以看到，在 $t- \tau$ 范围内本地节点的滞后是可以容忍的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>没有被选中的节点也可以参与迭代。&lt;/p>
&lt;p>没有被选中的节点也可以上传更新。这部分不会被直接合并，而是会通过一个bypass结构影响下一轮。
一个cache用来保存那些选中的节点上传的更新，没被选中的节点的更新保存在bypass中。bypass会在汇聚步骤完成后和cache合并,使得实际的有影响节点比率比参数C决定的更高。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="compensatory-first-come-first-merge-cfcfm-client-selection">Compensatory First-Come-First-Merge (CFCFM) client selection&lt;/h4>
&lt;p>代替必须等待所有选中节点上传更新，SAFA采用&lt;strong>先来先合并&lt;/strong>方法，只要上传的更新达到所需要的比率（是不是意味着可以上传的节点大于实际所需要的节点）就可以执行合并操作。&lt;/p>
&lt;p>给予那些参与较少的客户更高的优先级。在每一轮中，服务器都会维护一个错过上一轮训练的客户端的 id 列表，它们上传的更新会优先选择。&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/14/h6bZz4YPaOc87rf.png" alt="">&lt;/p>
&lt;h4 id="discriminative-aggregation">Discriminative Aggregation&lt;/h4>
&lt;p>聚合算法如下:&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/15/UlZErVnbgSC5KHG.png" alt="">&lt;/p>
&lt;p>对于选择的客户端，它们的更新将在合并到全局模型后保留在缓存中。对于未选择的客户端，更新不会在本轮生效，但会被缓存带入下一轮。对于崩溃的客户端，只有在它们没有被弃用的情况下，它们的模型才会保持不变。&lt;/p>
&lt;h4 id="算法流程">算法流程&lt;/h4>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/15/kxSZgVusbUM29hY.png" alt="">&lt;/p>
&lt;p>每轮开始时，服务器先检查客户端的模型，根据给定的超参数$\tau$和滞后容忍算法来分配模型。服务器收集上传的更新，错过上次更新的节点会被优先采集。等采集到的更新满足预先设置的标准后，执行三步合并，然后更新缓存状态。&lt;/p>
&lt;h2 id="iot-22a-blockchain-based-model-migration-approach-for-secure-and-sustainable-federated-learning-in-iot-systems">IOT ‘22《A Blockchain-based Model Migration Approach for Secure and Sustainable Federated Learning in IoT Systems》&lt;/h2>
&lt;h3 id="背景-2">背景&lt;/h3></description></item><item><title>联邦学习综述</title><link>https://chi-kai.github.io/post/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/</link><pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate><guid>https://chi-kai.github.io/post/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/</guid><description>&lt;h2 id="什么是联邦学习">什么是联邦学习&lt;/h2>
&lt;p>本质：联邦学习本质上是一种分布式机器学习技术，或机器学习框架。&lt;/p>
&lt;p>目标：联邦学习的目标是在保证数据隐私安全及合法合规的基础上，实现共同建模，提升AI模型的效果。&lt;/p>
&lt;h2 id="前置知识">前置知识:&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>IID：&lt;strong>独立同分布，表示一组随机变量的概率分布都相同，而且相互独立。例如掷色子。联邦学习背景下，数据集是非独立同分布的。&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>SGD: 梯度下降算法&lt;/p>
&lt;ul>
&lt;li>
&lt;p>绝大多数机器学习模型都有一个损失函数，来衡量预测值与实际值的差异。损失函数的值越小，模型的精确度就越高。通过使用梯度下降来调节参数，进而最小化损失函数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>损失函数里一般有两种参数，一种是控制输入信号量的权重(Weight, 简称 w ），另一种是调整函数与真实值距离的偏差（Bias，简称 b ）。我们所要做的工作，就是通过梯度下降方法，不断地调整权重 w 和偏差b，使得损失函数的值变得越来越小。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>通过计算梯度可以找到下降的方向，然后通过学习率a来控制下降的快慢。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-fallback" data-lang="fallback">&lt;span style="display:flex;">&lt;span>def train(X, y, W, B, alpha, max_iters):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    &amp;#39;‘’
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    选取所有的数据作为训练样本来执行梯度下降
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    X : 训练数据集
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    y : 训练数据集所对应的目标值
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    W : 权重向量
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    B ： 偏差变量
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    alpha ： 学习速率
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    max_iters : 梯度下降过程最大的迭代次数
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   &amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   dW = 0 # 初始化权重向量的梯度累加器
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   dB = 0 # 初始化偏差向量的梯度累加器
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   m = X.shape[0] # 训练数据的数量
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>  
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   # 开始梯度下降的迭代
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   for i in range(max_iters):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       dW = 0 # 重新设置权重向量的梯度累加器
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       dB = 0 # 重新设置偏差向量的梯度累加器
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>      
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       # 对所有的训练数据进行遍历
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       for j in range(m):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>           # 1. 遍历所有的训练数据
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>           # 2. 计算每个训练数据的权重向量梯度w_grad和偏差向量梯度b_grad
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>           # 3. 把w_grad和b_grad的值分别累加到dW和dB两个累加器里
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>      
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       W = W - alpha * (dW / m) # 更新权重的值
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       B = B - alpha * (dB / m) # 更新偏差的值
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    return W, B # 返回更新后的权重和偏差。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="优化过程">优化过程&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>固定总数 K 个客户端，每个客户端都有本地数据集。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每次选取分数 C （比例）个客户端&lt;/p>
&lt;/li>
&lt;li>
&lt;p>服务器将当前的全局算法发送给每个客户端。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个被选定的客户端执行本地计算，并将服务器更新。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="通信成本占主导">通信成本占主导&lt;/h2>
&lt;p>一般数据中心中，通讯花费占少数，计算花费占大头。但是在联邦优化中，通讯占主导地位&lt;/p>
&lt;ul>
&lt;li>
&lt;p>通常上传带宽被限制到1MB或者更低。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>客户端只有在&lt;strong>充电，插入电源，和有不限量WIFI&lt;/strong>的情况下才会参与到优化过程中来。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>希望每个客户每天只参加少量的更新回合&lt;/strong>。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>因为单个客户端的训练数据很小，而且当前智能手机等客户端的计算能力是足够强的，所以&lt;strong>通过使用额外的计算量来减少通信的次数&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>增加并行量&lt;/strong>。在每次通信过程中，使用更多客户端来更新。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>增加每个客户端的计算量&lt;/strong>。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="联邦平均算法">联邦平均算法&lt;/h2>
&lt;p>联邦背景下，对梯度下降算法的扩展。&lt;/p>
&lt;p>选取K个Client，Server将当前的参数传递给Client,Client根据本地数据集和参数来进行梯度下降。&lt;/p>
&lt;p>最后将训练后的参数返回给Server,Server将获得的所有参数加权处理后得到最终的参数。然后再进行下一轮计算。&lt;/p>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7of7bwegjj30re0p00ym.jpg" alt="fedsvg.png">&lt;/p>
&lt;p>如图所示，当B $\rightarrow$ $\infty$，E $\rightarrow$ 1  表示本地数据全部参与训练，只训练一次，称为FedSGD。&lt;/p>
&lt;h2 id="分类">分类&lt;/h2>
&lt;p>我们把每个参与共同建模的企业称为参与方，根据多参与方之间数据分布的不同，把联邦学习分为三类：横向联邦学习、纵向联邦学习和联邦迁移学习。&lt;/p>
&lt;h3 id="横向联邦学习">横向联邦学习&lt;/h3>
&lt;p>横向联邦学习的本质是 &lt;strong>样本的联合&lt;/strong>，适用于参与者间业态相同但触达客户不同，即特征重叠多，用户重叠少时的场景，比如不同地区的银行间，他们的业务相似（特征相似），但用户不同（样本不同）&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/29/DbjBYyxuRgdhQrF.png" alt="">&lt;/p>
&lt;h4 id="学习过程">学习过程:&lt;/h4>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/29/Myue2zbxD9JIs1Z.png" alt="">&lt;/p>
&lt;ul>
&lt;li>参与方各自从服务器A下载最新模型&lt;/li>
&lt;li>每个参与方利用本地数据训练模型，加密梯度上传给服务器A，服务器A聚合各用户的梯度更新模型参数；&lt;/li>
&lt;li>服务器A返回更新后的模型给各参与方；&lt;/li>
&lt;li>各参与方更新各自模型。&lt;/li>
&lt;/ul>
&lt;h3 id="纵向联邦学习">纵向联邦学习&lt;/h3>
&lt;p>纵向联邦学习的本质是 &lt;strong>特征的联合&lt;/strong>，适用于用户重叠多，特征重叠少的场景，比如同一地区的商超和银行，他们触达的用户都为该地区的居民（样本相同），但业务不同（特征不同）。&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/29/9RFpChvgXyAMSBY.png" alt="">&lt;/p>
&lt;h4 id="学习过程-1">学习过程&lt;/h4>
&lt;p>纵向联邦学习的本质是交叉用户在不同业态下的特征联合，比如商超A和银行B，在传统的机器学习建模过程中，需要将两部分数据集中到一个数据中心，然后再将每个用户的特征join成一条数据用来训练模型，所以就需要双方有用户交集（基于join结果建模），并有一方存在label。其学习步骤如上图所示，分为两大步：&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/29/tOUj1Jx6MyslKL7.png" alt="">&lt;/p>
&lt;p>第一步：加密样本对齐。是在系统级做这件事，因此在企业感知层面不会暴露非交叉用户。&lt;/p>
&lt;p>第二步：对齐样本进行模型加密训练：&lt;/p>
&lt;ul>
&lt;li>由第三方C向A和B发送公钥，用来加密需要传输的数据；&lt;/li>
&lt;li>A和B分别计算和自己相关的特征中间结果，并加密交互，用来求得各自梯度和损失；&lt;/li>
&lt;li>A和B分别计算各自加密后的梯度并添加掩码发送给C，同时B计算加密后的损失发送给C；&lt;/li>
&lt;li>C解密梯度和损失后回传给A和B，A、B去除掩码并更新模型。&lt;/li>
&lt;/ul>
&lt;h3 id="联邦迁移学习">联邦迁移学习&lt;/h3>
&lt;p>当参与者间特征和样本重叠都很少时可以考虑使用联邦迁移学习，如不同地区的银行和商超间的联合。主要适用于以深度神经网络为基模型的场景。&lt;/p>
&lt;p>迁移学习，是指利用数据、任务、或模型之间的相似性，将在源领域学习过的模型，应用于 目标领域的一种学习过程。&lt;/p></description></item></channel></rss>