<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>论文阅读 on 悉达多</title><link>https://chi-kai.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link><description>Recent content in 论文阅读 on 悉达多</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 19 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://chi-kai.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://chi-kai.github.io/post/%E6%A8%A1%E5%9E%8B%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link><pubDate>Thu, 19 Sep 2024 00:00:00 +0000</pubDate><guid>https://chi-kai.github.io/post/%E6%A8%A1%E5%9E%8B%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</guid><description>&lt;h1 id="ccs24-badmerging-backdoor-attacks-against-model-merging">CCS'24 BadMerging: Backdoor Attacks Against Model Merging&lt;/h1>
&lt;h2 id="摘要">摘要&lt;/h2>
&lt;p>随着预训练模型在下游任务中的广泛应用，&lt;strong>模型融合&lt;/strong>（Model Merging, MM）作为一种有效的知识转移方法应运而生。MM通过合并多个独立微调的任务特定模型来构建一个能够处理多种任务的增强型模型。然而，这种方法可能引入安全风险，尤其是后门攻击。后门攻击允许攻击者通过在训练数据中注入恶意触发器来破坏机器学习模型。在本文中，我们首次提出了BadMerging，这是一种专门针对模型融合的后门攻击方法。&lt;strong>BadMerging通过两阶段攻击机制和一种新颖的特征插值损失函数，即使在合并参数变化时，也能增强嵌入后门的鲁棒性&lt;/strong>。我们的方法不仅能够对攻击者提供的任务（on-task attack）进行攻击，还能对其他贡献者提供的任务（off-task attack）进行攻击。广泛的实验表明，BadMerging对各种模型融合算法都具有显著的攻击效果，并且现有的防御机制无法有效防御我们的攻击，这突显了需要更高级防御机制的必要性。&lt;/p>
&lt;h2 id="背景">背景&lt;/h2>
&lt;p>模型融合（MM）是一种新兴的技术，它通过合并多个微调后的任务特定模型来提高模型在多个任务上的性能。这种方法的优势在于能够利用已有的模型和知识，减少存储成本和计算资源，同时提高模型的通用性和性能。 MM 不需要来自多个任务的训练数据，而是通过&lt;strong>合并权重&lt;/strong>来组合多个经过微调的特定于任务的模型，这些模型共享相同的模型架构。
![[Pasted image 20241020172630.png]]
然而，这种合并过程也带来了安全隐患。如果合并的模型中包含了被恶意修改的模型，那么整个合并后的模型可能会继承这些安全漏洞，从而受到攻击者的控制。&lt;strong>尽管模型融合的实用性已经得到了广泛认可，但其安全性问题却鲜有研究。&lt;/strong>&lt;/p>
&lt;p>与经典后门攻击不同，MM中对手只能贡献合并模型的一部分（例如，一个特定于任务的模型），而且==不能完全访问合并过程==。现有的后门攻击尽管能够有效地对单个特定任务模型进行后门处理，但都无法对合并模型进行后门处理（攻击成功率&amp;lt;20%）。我们发现这是&lt;strong>因为每个模型在合并过程中都会通过其合并系数重新缩放，并且==当系数小时后门会消失&lt;/strong>==&lt;/p>
&lt;p>BadMerging的关键思想是&lt;strong>设计一种与合并系数变化无关的后门机制&lt;/strong>。&lt;/p>
&lt;p>BadMerging 进一步引入了&lt;strong>on-task和off-task&lt;/strong>后门攻击的概念。on-task攻击会给攻击者提供的任务加入后门，而off-task攻击则会给由其他（良性）模型提供者提供的任务加入后门。这些攻击涵盖了MM的所有应用场景。在off-task攻击中，由于对手可能不知道将合并哪些任务，BadMerging 旨在将触发图像分类为对手为包含此类的任何任务选择的类。&lt;/p>
&lt;h2 id="相关工作">相关工作&lt;/h2>
&lt;h3 id="预训练模型">预训练模型&lt;/h3>
&lt;p>所有现有的模型合并工作都是在类似 &lt;strong>CLIP&lt;/strong> 的预训练模型上进行的
&lt;strong>CLIP&lt;/strong> 是一个联合的图像和文本嵌入模型，通过 4 亿个图像和文本对以自监督的方式进行训练。这意味着它将文本和图像映射到同一个嵌入空间中。例如，一张狗的图片和句子“一张狗的图片”将具有非常相似的嵌入，并在向量空间中彼此接近。
&lt;strong>CLIP&lt;/strong>模型通过计算文本和图像向量之间的余弦相似度来生成预测。这种模型特别适用于零样本学习任务，即模型不需要看到新的图像或文本的训练示例就能进行预测
CLIP $\mathcal{M}$包括视觉编码器$\mathcal{V}$ 和文本编码器$T$,当计算一个输入$x$在目标类型空间$C$中的得分:
$$\mathcal{M}(x, C)=\left[\left\langle\mathcal{V}(x), \mathcal{T}\left(c_{1}\right)\right\rangle, \cdots,\left\langle\mathcal{V}(x), \mathcal{T}\left(c_{k}\right)\right\rangle\right]^{\top}$$
微调CLIP时，使用交叉熵函数来优化模型权重，其中$y$是真实标签:
$$Loss(\mathcal{M}(x,C),y)$$&lt;/p>
&lt;h3 id="模型合并">模型合并&lt;/h3>
&lt;p>$$\theta = \theta &lt;em>{pre} + \lambda {\textstyle \sum&lt;/em>{i=1}^{n}} \theta _{i}$$&lt;/p>
&lt;h2 id="方案设计">方案设计&lt;/h2>
&lt;p>![[Pasted image 20241018105016.png]]
假设一个合并模型的结构如下:
$$\begin{aligned}\theta_{\text {merged }} &amp;amp; =\theta_{\text {pre }}+\sum_{i \neq \text { adv }} \lambda_{i} \cdot \Delta \theta_{i}+\lambda_{\mathrm{adv}} \cdot \Delta \theta_{\mathrm{adv}} \&amp;amp; =\theta_{\text {pre }}+\Delta \theta_{\mathrm{benign}}+\lambda_{\mathrm{adv}} \cdot \Delta \theta_{\mathrm{adv}}\end{aligned}$$
BadMerging攻击框架包含两个主要部分：攻击机制设计和特征插值损失函数。&lt;/p>
&lt;ol>
&lt;li>&lt;strong>两阶段攻击机制&lt;/strong>：BadMerging首先在第一阶段生成一个通用触发器，该触发器能够在合并参数为0时激活后门。然后在第二阶段，攻击者使用这个触发器来微调其任务特定模型，确保在合并参数为1时攻击有效。这样，攻击在合并参数从0到1的任何值下都能保持有效。&lt;/li>
&lt;li>&lt;strong>特征插值损失函数&lt;/strong>：为了增强触发器在不同合并参数下的鲁棒性，提出了一种新颖的特征插值损失函数。该损失函数通过插值触发器图像的特征，强制模型在不同合并参数下都将触发器图像分类为目标类别。&lt;/li>
&lt;/ol>
&lt;h3 id="on-task">on-task&lt;/h3>
&lt;p>目标任务与攻击者任务相同。比如说攻击者的模型任务是猫狗识别，后门就是将猫识别为🐖。BadMerging-On 目的是&lt;strong>迫使最终的合并模型在执行攻击者任务时按照攻击者的意愿行事&lt;/strong>
这里假设两个场景:（1） 多任务学习场景意味着合并来自不同领域的任务向量以进行多任务学习（2）单任务学习场景意味着合并来自同一领域的任务向量以提高效用&lt;/p>
&lt;ul>
&lt;li>Step1: 优化通用触发器，该触发器能够在合并参数为0时激活后门。$\lambda_{adv}=0$ 时损失函数如下:
$$\underset{t}{\arg \min } \sum_{x \in \mathcal{D}&lt;em>{\mathrm{tgt}}} \mathcal{L}&lt;/em>{C E}\left[\mathcal{M}&lt;em>{\left(\theta&lt;/em>{\mathrm{pre}}+\Delta \theta_{\text {benign }}\right)}\left(x \oplus t, C_{\mathrm{tgt}}\right),c\right]$$
作者观察到不同任务的任务向量是正交的。由于攻击者不知道$\Delta \theta_{benign }$ ，可以使用$\theta_{pre}$ 来代替。
$$\underset{t}{\arg \min } \sum_{x \in \mathcal{D}&lt;em>{\mathrm{tgt}}} \mathcal{L}&lt;/em>{C E}\left[\mathcal{M}&lt;em>{\theta&lt;/em>{\mathrm{pre}}}\left(x \oplus t, C_{\mathrm{tgt}}\right), c\right]$$&lt;/li>
&lt;li>Step2: 微调其任务特定模型，确保在合并参数为1时攻击有效。$\lambda_{adv}=1$ 时损失函数如下：
$$\frac{1}{\left|\mathcal{D}&lt;em>{\mathrm{adv}}\right|} \sum&lt;/em>{(x, y) \in \mathcal{D}&lt;em>{\mathrm{adv}}}\left[\mathcal{L}&lt;/em>{C E}\left(\mathcal{M}&lt;em>{\theta&lt;/em>{\mathrm{adv}}}\left(x, C_{\mathrm{adv}}\right), y\right)+\alpha \cdot \mathcal{L}&lt;em>{B D}(x, c, t)\right]$$
现在模型在系数为0和1时可以触发后门，但是有的中间值不能触发后门。所以引入插值损失函数:
$$\begin{array}{l}F=p \cdot \mathcal{V}&lt;/em>{\theta_{\text {adv }}}(x \oplus t)+(1-p) \cdot \mathcal{V}&lt;em>{\theta&lt;/em>{\mathrm{pre}}}(x \oplus t), \\mathcal{L}&lt;em>{B D}(x, c, t)=\mathcal{L}&lt;/em>{C E}\left(\left[\left\langle F, \mathcal{T}\left(c_{1}\right)\right\rangle, \cdots,\left\langle F, \mathcal{T}\left(c_{k}\right)\right\rangle\right]^{\top}, c\right) .\end{array}$$
对于 λadv = 1，我们使用 Mθadv 的视觉编码器提取的特征来近似合并模型的特征。对于 λadv = 0，由于对手不知道 Δθbenign，我们使用 Mθpre 的视觉编码器提取的特征来近似合并模型的特征。&lt;/li>
&lt;/ul>
&lt;h3 id="off-task">off-task&lt;/h3>
&lt;p>目标任务与攻击者任务不同。假设目标&lt;/p>
&lt;h2 id="实验结果">实验结果&lt;/h2>
&lt;p>我们的实验设计包括了多种模型融合算法，以及与现有后门攻击方法的比较。实验结果表明：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>攻击效果&lt;/strong>：BadMerging在多种模型融合算法下都能实现高达90%以上的攻击成功率，显著优于现有方法。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>防御机制评估&lt;/strong>：我们评估了现有的检测和防御机制，包括Neural Cleanse和Fine-pruning，结果表明这些机制无法有效防御BadMerging攻击。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="自己思考">自己思考&lt;/h2>
&lt;p>&lt;strong>优点&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>BadMerging是首个针对模型融合的后门攻击框架，填补了该领域的研究空白。&lt;/li>
&lt;li>通过两阶段攻击机制和特征插值损失函数，BadMerging展示了对不同合并参数的鲁棒性。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>缺点&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>BadMerging需要对攻击者的任务特定模型进行微调，这可能需要较大的计算资源。&lt;/li>
&lt;li>论文中没有详细讨论攻击在不同规模和复杂度的模型上的效果。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>未来改进的方向&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>探索在更大规模的数据集和模型上的攻击效果，以及如何优化攻击策略以减少资源消耗。&lt;/li>
&lt;li>研究如何结合多种防御机制来提高模型融合的安全性。&lt;/li>
&lt;li>考虑实际部署场景，研究如何在不牺牲太多性能的情况下提高模型的鲁棒性。&lt;/li>
&lt;/ul>
&lt;h2 id="idea-多源模型版权保护">idea: 多源模型版权保护。&lt;/h2>
&lt;p>在模型融合过程中，关注每个融合模型的版权。比如a + b + c。每个模型所有者的版权都能查到。
&lt;strong>可能的挑战&lt;/strong>： 1. 版权冲突 a / b / c 后门水印冲突
2. 水印容量
3.&lt;/p>
&lt;h1 id="ccs24-neural-dehydration-effective-erasure-of-black-box-watermarks-from-dnns-with-limited-data">CCS'24 Neural Dehydration: Effective Erasure of Black-box Watermarks from DNNs with Limited Data&lt;/h1>
&lt;h2 id="摘要-1">摘要&lt;/h2>
&lt;p>本文提出了一种名为“Neural Dehydration”（简称Dehydra）的新型攻击框架，旨在有效移除深度神经网络（DNN）中的黑盒水印。黑盒水印是一种保护DNN知识产权的技术，通过在特定样本集上嵌入水印信息，并在疑似模型中提取水印以验证所有权。现有的水印移除攻击通常需要大量数据或对水印结构有先验知识，但这些攻击往往只能破解一小部分主流黑盒水印，且可能损害模型效用或依赖于大量数据。Dehydra通过利用DNN的内部结构来恢复和忘却水印信息，有效移除了所有十种主流黑盒水印，且只需有限或甚至不需要数据。具体来说，Dehydra首先使用模型反演技术恢复接近真实水印数据的样本，然后在微调过程中故意忘却这些样本。此外，Dehydra还引入了目标类别检测和恢复样本分割算法，以减少效用损失并实现无数据水印移除。在三个基准数据集和DNN架构上的广泛评估表明，Dehydra在数据有限的设置下，至少保留了90%的模型效用，同时实现了对所有覆盖水印的强效移除效果。&lt;/p>
&lt;h2 id="背景-1">背景&lt;/h2>
&lt;p>随着深度学习技术的快速发展，训练一个高性能的DNN模型变得越来越重要。然而，模型训练需要大量的数据收集和计算资源。为了保护这些训练好的模型不被非法复制或滥用，模型水印技术应运而生。水印技术通过在模型训练过程中嵌入特定的信息，使得在模型被非法使用时能够追踪到原始所有者。黑盒水印因其验证过程只需API访问而受到广泛关注。然而，现有的水印技术面临着被攻击者移除的风险，攻击者可能会通过修改模型参数来使水印失效。尽管已有研究提出了多种水印移除攻击，但这些攻击往往需要大量数据或对水印结构有深入了解，这在实际场景中是不现实的。因此，本文提出了一种无需数据或只需有限数据的水印移除攻击方法，旨在提高攻击的实用性和有效性。&lt;/p>
&lt;h2 id="相关工作-1">相关工作&lt;/h2>
&lt;p>在DNN模型水印领域，已有多种水印嵌入和提取技术被提出。这些技术主要分为白盒水印和黑盒水印两大类。白盒水印需要对模型内部参数进行访问，而黑盒水印则只需通过模型的预测行为进行验证。此外，针对水印的安全性，研究者们还提出了多种攻击方法，包括基于剪枝、微调和反学习的攻击。这些攻击方法试图通过修改模型参数或训练数据来移除水印，但它们通常需要大量数据或对水印算法有先验知识。最近，一些研究开始关注在数据受限条件下的水印移除问题，提出了一些新的攻击策略。然而，这些方法在实际应用中仍存在局限性，如攻击效果不佳或对数据的依赖性仍然较高。本文提出的Dehydra方法正是为了解决这些问题，通过利用模型内部信息来实现有效的水印移除，同时减少对外部数据的依赖。&lt;/p>
&lt;h2 id="方案设计-1">方案设计&lt;/h2>
&lt;p>![[Pasted image 20241018115506.png]]
Dehydra攻击框架主要包含两个阶段：&lt;strong>水印恢复和水印忘却&lt;/strong>。在水印恢复阶段，Dehydra使用模型反演技术从目标水印模型中恢复出接近真实水印数据的样本。这一阶段利用了DNN的过参数化特性，通过优化技术重建与目标类别相关联的水印信息。在水印忘却阶段，Dehydra在微调过程中故意忘却这些恢复出的样本，以此来移除水印。为了提高攻击的有效性和减少对数据的依赖，Dehydra进一步引入了目标类别检测和恢复样本分割算法。目标类别检测算法通过分析模型的损失景观来识别固定类别的水印，并检测其目标类别。恢复样本分割算法则基于正常数据优势现象，将恢复样本分割为代理水印数据和代理正常数据，以确保在移除水印的同时保持模型的原始效用。Dehydra的这些设计使其能够在数据受限的条件下实现有效的水印移除。&lt;/p>
&lt;h2 id="实验结果-1">实验结果&lt;/h2>
&lt;p>实验部分首先介绍了实验的设计，包括使用的数据集、DNN架构、水印算法和攻击方法。作为基线的攻击方法包括剪枝、微调和反学习等。实验结果表明，Dehydra在数据有限的设置下，能够实现对所有十种主流黑盒水印的强效移除，同时至少保留了90%的模型效用。与现有攻击方法相比，Dehydra在移除水印方面表现出更高的有效性，且对模型效用的影响更小。&lt;/p>
&lt;h2 id="自己思考-1">自己思考&lt;/h2>
&lt;p>本文提出的Dehydra方法在水印移除领域具有创新性，特别是在减少对数据依赖和提高攻击有效性方面。然而，该方法也有一些局限性。首先，Dehydra主要针对图像分类任务，对于其他类型的DNN模型，如自然语言处理模型，其有效性尚未得到验证。其次，Dehydra的攻击效果可能受到模型结构和水印算法设计的影响，对于某些特定的水印算法，可能需要进一步调整攻击策略。未来的工作可以探索Dehydra在其他任务和模型上的应用，并研究如何提高其对不同水印算法的适应性。此外，研究者们还可以探索如何结合Dehydra与其他攻击方法，以实现更全面的水印防御策略。&lt;/p>
&lt;h2 id="eccv24-revocable-backdoor-for-deep-model-trading">ECCV'24 Revocable Backdoor for Deep Model Trading&lt;/h2>
&lt;h2 id="摘要-2">摘要&lt;/h2>
&lt;p>本文提出了一种新型的可撤销后门（revocable backdoor）概念，并将其应用于深度模型交易场景中。在深度模型交易中，卖家希望在不泄露模型核心价值的情况下，让买家评估模型性能；而买家则希望在不满意时能够退回模型并获得退款。为了解决这一矛盾，作者设计了一种特殊的后门，该后门在植入时不会降低模型性能，且卖家可以在任何时候通过特定的掩码矩阵（mask matrices）轻松撤销后门，而无需重新训练模型。这种可撤销后门不仅能够保护卖家的利益，防止买家在未完成最终支付时滥用模型，同时也能保证买家在支付最终款项后获得一个干净的模型。通过在多个数据集和网络架构上的实验，作者证明了该可撤销后门的可行性和鲁棒性。&lt;/p>
&lt;h2 id="背景-2">背景&lt;/h2>
&lt;p>深度学习模型在多个领域取得了显著的成就，成为重要的数字产品。然而，这些模型容易受到后门攻击的威胁，攻击者通过在训练阶段植入后门，使得模型在特定触发器出现时返回攻击者期望的结果。这种攻击严重破坏了深度模型的可信度。尽管后门攻击通常被视为安全威胁，但也有研究者利用后门攻击进行正向目的，如模型版权保护、人工智能可解释性和对抗性示例防御等。本文首次提出可撤销后门的概念，将其应用于深度模型交易，旨在在不降低模型性能的前提下，实现对后门的控制，同时保护买卖双方的利益。&lt;/p>
&lt;h2 id="相关工作-2">相关工作&lt;/h2>
&lt;p>在机器学习安全领域，后门攻击和防御是两个重要的研究方向。后门攻击的目标是让深度模型在触发器出现时返回攻击者期望的结果。早期的后门攻击如BadNets通过在训练阶段的数据投毒实现攻击，而后续的研究则探索了更隐蔽的触发器模式。除了基于数据投毒的后门攻击，还有通过控制训练过程实现的后门攻击。这些攻击方法在隐蔽性和攻击效果上有所不同，但都需要在模型中留下痕迹。&lt;/p>
&lt;p>针对后门攻击的威胁，后门防御技术也迅速发展。后门检测技术旨在确定模型是否包含后门，而后门净化技术则旨在在不显著降低模型性能的前提下消除后门。例如，Neural Cleanse通过分析模型的异常行为来检测后门，而Fine-Pruning则通过网络剪枝来消除后门。这些防御技术在检测和清除后门方面取得了一定的效果，但也存在局限性。&lt;/p>
&lt;h2 id="方案设计-2">方案设计&lt;/h2>
&lt;p>本文提出的可撤销后门方案主要包括以下几个模块：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>模型训练与后门植入&lt;/strong>：在模型训练阶段，通过在部分干净图像上添加触发器模式并将其标记为目标标签，生成有毒数据集。然后，使用这些有毒数据训练模型，同时更新触发器模式，以确保模型在触发器出现时返回错误的结果。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>掩码矩阵设计&lt;/strong>：为了实现后门的可撤销性，作者设计了掩码矩阵来控制模型的内部特征图。这些掩码矩阵可以在不重新训练模型的情况下，通过改变模型的内部特征图来撤销后门。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>触发器模式优化&lt;/strong>：为了平衡触发器模式的隐蔽性和攻击鲁棒性，作者提出了一种触发器模式的微调方法。通过调整触发器模式的参数，可以在保持触发器模式隐蔽性的同时，提高攻击的有效性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>现有后门攻击的撤销方法&lt;/strong>：对于已经存在的后门攻击，作者提出了一种后门擦除方法，通过最小化干净和有毒图像之间的交叉熵损失来撤销后门。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="实验结果-2">实验结果&lt;/h2>
&lt;p>实验设计包括三个数据集：CIFAR-10、GTSRB和Sub-ImageNet，以及两种网络架构：ResNet-18和VGG。实验中，作者将提出的可撤销后门方法与多种现有的后门攻击方法进行了比较，包括BadNets、Blend、SIG、LSB、WaNet和BppAttack。实验结果表明，提出的可撤销后门方法在攻击有效性、模型保真度和后门可撤销性方面均优于现有方法。在没有防御措施的情况下，可撤销后门能够显著降低模型在有毒输入下的准确性，同时保持在干净输入下的准确性不变。此外，通过引入掩码矩阵，模型能够恢复到干净模型的性能水平。&lt;/p>
&lt;h2 id="自己思考-2">自己思考&lt;/h2>
&lt;p>本文的优点在于提出了一种创新的可撤销后门概念，并将其成功应用于深度模型交易场景。这种方法不仅能够保护卖家的利益，防止未授权使用，同时也能保证买家在支付最终款项后获得一个干净的模型。此外，实验结果表明，该方法在多个数据集和网络架构上都具有很好的可行性和鲁棒性。&lt;/p>
&lt;p>然而，该方法也存在一些局限性。例如，可撤销后门的实现依赖于掩码矩阵的设计，这可能需要对模型的内部结构有深入的了解。此外，该方法在面对更复杂的防御策略时，其有效性可能会受到影响。&lt;/p>
&lt;p>未来的改进方向可以包括：1) 探索更加隐蔽的触发器模式，以提高后门的隐蔽性；2) 研究更加高效的后门撤销方法，以减少对模型性能的影响；3) 考虑在更广泛的攻击和防御场景下，评估可撤销后门的适用性和有效性。&lt;/p></description></item><item><title>区块链白皮书解读</title><link>https://chi-kai.github.io/post/%E5%8C%BA%E5%9D%97%E9%93%BE%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/</link><pubDate>Fri, 25 Nov 2022 00:00:00 +0000</pubDate><guid>https://chi-kai.github.io/post/%E5%8C%BA%E5%9D%97%E9%93%BE%E7%99%BD%E7%9A%AE%E4%B9%A6%E8%A7%A3%E8%AF%BB/</guid><description>&lt;h2 id="比特币白皮书">比特币白皮书&lt;/h2>
&lt;h2 id="以太坊白皮书">以太坊白皮书&lt;/h2>
&lt;h2 id="tangle-白皮书">Tangle 白皮书&lt;/h2>
&lt;p>详细的内容见 &lt;a href="https://lzphi.cn/2020/12/20/2020-12-17-Tangle-%E7%99%BD%E7%9A%AE%E4%B9%A6/">Tangle白皮书中文版&lt;/a>&lt;/p>
&lt;p>&lt;strong>tangle&lt;/strong> 是 &lt;strong>IOTA&lt;/strong> 所用的技术，为物联网和小额支付提供支持。不同于常见的区块链，它使用一个DAG（有向无环图）作为结构，这里称为Tangle。&lt;/p>
&lt;p>传统区块链系统的单链结构在交易认证，吞吐量，资源消耗等方面存在缺陷，DAG结构的区块链是一个有效的解决方案。&lt;/p>
&lt;h2 id="fabric-白皮书">Fabric 白皮书&lt;/h2>
&lt;p>&lt;strong>Hyperledger Fabric&lt;/strong> 是 Linux 基金会 的 一个项目，是Hyperledger下面的一个子项目。作为一个开源联盟链，被很多项目应用。&lt;/p>
&lt;p>它的主要特点是模块化的共识机制，相对高性能，和可以使用常规语言编写智能合约(golang)。&lt;/p>
&lt;h3 id="概念">概念&lt;/h3>
&lt;h4 id="联盟链">联盟链&lt;/h4>
&lt;p>文中划分联盟链和公链的标准是: &lt;strong>是否发币和节点身份是否可知&lt;/strong>&lt;/p>
&lt;p>状态机复制(SMR)是建设弹性应用众所周知的方式，但是如果我们把运行在区块链上的智能合约看作一种分布式应用，与传统的SMR区别在于:&lt;/p>
&lt;ul>
&lt;li>许多应用并发运行&lt;/li>
&lt;li>这些应用可以被任何人动态地部署&lt;/li>
&lt;li>这些应用的代码是不被信任的，可能有恶意&lt;/li>
&lt;/ul>
&lt;h4 id="order-execute">order-execute&lt;/h4>
&lt;p>现有的大部分可以运行智能合约的区块链遵循SMR实现一种order-execute的架构: 节点先将交易排序再将它们广播给其他节点，然后每个节点顺序执行。&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/12/06/B4Ns3GZAKl8dIXT.png" alt="">&lt;/p>
&lt;p>这个架构存在的一些问题:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>所有节点按照顺序执行交易会限制性能（例如TPS），通常将不相关的操作并发执行可以提升性能，但是对智能合约很难做到并发，因为代码之间的依赖关系很难确定&lt;/p>
&lt;/li>
&lt;li>
&lt;p>order-execute最大的限制是，所有节点所执行的交易必须满足确定性.类似以太坊这样采用Solidity这样的编程语言可以一定程度上保证代码确定性，但对于更流行的语言（例如Go，Java，C/C++），则很难保证确定性（比如Go中的map iterator就无法保证确定性）。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="execute-order-validate">execute-order-validate&lt;/h4>
&lt;p>&lt;img src="https://s2.loli.net/2022/12/07/jDBxcLmYrfXSnbl.png" alt="">&lt;/p></description></item><item><title>DAG区块链论文阅读</title><link>https://chi-kai.github.io/post/dag%E5%8C%BA%E5%9D%97%E9%93%BE%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link><pubDate>Thu, 10 Nov 2022 00:00:00 +0000</pubDate><guid>https://chi-kai.github.io/post/dag%E5%8C%BA%E5%9D%97%E9%93%BE%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</guid><description>&lt;h2 id="direct-acyclic-graph-based-ledger-for-internet-of-things-performance-and-security-analysis">《Direct Acyclic Graph-Based Ledger for Internet of Things: Performance and Security Analysis》&lt;/h2>
&lt;h3 id="问题背景">问题背景&lt;/h3>
&lt;p>由于区块链的安全性，去中心化，可信性，在IoT系统上有可观的应用前景（如智能车，能源交易）。IoT系统具有规模大，资源受限的特性。所以其上的共识算法必须满足资源需求小,低消耗，和高的交易吞吐量。&lt;/p>
&lt;p>现在主要的两种共识算法:PoW需要高的资源消耗，PoS的币龄证明可能造成垄断和中心化。&lt;/p>
&lt;p>典型的区块链是一种单链结构，为了避免非法的fork，应用的共识算法必须降低新的block生成速率。这导致了吞吐量瓶颈和区块认证延迟的问题，在IoT系统上又有交易花费高和资源消耗大的问题。&lt;/p>
&lt;p>DAG共识算法可以允许任何节点可以立即向ledger插入一个新的block，前提是它能先处理更早的交易。这种方式会造成很多fork，DAG有很多算法来避免在传统区块链上面临的double-spending问题(Markov Chain Monte Carlo algorithm and virtual voting algorithm)。DAG共识算法的交易吞吐是不受限制的，而且资源消耗很低，这符合IoT的应用场景。&lt;/p>
&lt;h3 id="dag概述">DAG概述&lt;/h3>
&lt;h4 id="名词定义">名词定义&lt;/h4>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/19/auRt2FzeCjwgsGM.png" alt="">&lt;/p>
&lt;p>这里使用典型的Tangle算法来进行解释。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Block: 所有块是记录信息的存储单元(包括交易，数字签名，哈希值)，在Tangle里一个块记录一个交易&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Tip: 还没有被验证的块(交易)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Direct approval：直接验证，两个块直接由一条边来链接，称为直接验证。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>indirect approval：间接验证，两个块有通过一个块和&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Own weight: 与它的提出者的工作量有关&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cumulative weight: 代表一个交易的认证级别。是一个交易自身own weight以及它直接证明和间接证明的交易的交易own weight总和。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="共识过程">共识过程&lt;/h4>
&lt;ol>
&lt;li>节点创造一个块来储存交易&lt;/li>
&lt;li>节点通过MCMC tips 选择算法来选择两个没有冲突的tips，然后添加它们的hash到块中&lt;/li>
&lt;li>节点解决一个低难度的pow问题，来避免垃圾信息&lt;/li>
&lt;li>使用私钥给交易签名并广播，当其他节点收到时会检查是否合法&lt;/li>
&lt;li>成功添加的交易成为tip,等待被验证。直到它的cumulative weight 达到定义的标准。&lt;/li>
&lt;/ol>
&lt;h4 id="分叉问题">分叉问题&lt;/h4>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/19/VnrEiPCoslHG9KY.png" alt="">&lt;/p>
&lt;p>在分布式账本中，构建分叉以重做工作是篡改存储数据的唯一方法。基于此，double-spending的主要思想是将两笔相互冲突的交易并行放置在两条链上。在第一笔交易花费在服务上之后，攻击者扩展包含冲突交易的链并让它超过第一条链。当此操作成功时，第一笔交易将被孤立，攻击者可以多次使用token。&lt;/p>
&lt;ul>
&lt;li>单链模型: 以最长的一个链为标准，正常的矿工会在最长的链上工作&lt;/li>
&lt;li>DAG模型: 以累计权重最大的子图为标准，正常的节点会通过MCMC tips 选择算法扩展权重最大的链。&lt;/li>
&lt;/ul>
&lt;h3 id="heading">&lt;/h3>
&lt;h2 id="tips-transaction-inclusion-protocol-with-signaling-in-dag-based-blockchain">《TIPS: Transaction Inclusion Protocol with Signaling in DAG-based Blockchain》&lt;/h2>
&lt;h3 id="问题背景-1">问题背景&lt;/h3>
&lt;p>由于DAG区块链的高并发场景和网络延迟，矿工通常不能及时获取整个网络的更新信息，导致重复在一个并行区块包括相同的交易，在区块链中生成冗余的记录。这个交易包含冲突会浪费区块容量和降低系统性能。尽管DAG区块链已经限制交易的高并发，但是交易冲突的风险实际还会诱发&lt;strong>矿工收益&lt;/strong>和&lt;strong>系统吞吐&lt;/strong>的困境。&lt;/p>
&lt;h4 id="问题分析">问题分析&lt;/h4>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h804wzs4nsj30rk0jtgqa.jpg" alt="符号.png">&lt;/p>
&lt;p>三种交易包含策略:&lt;/p>
&lt;ol>
&lt;li>随机包含($P^{rand}$): $p_{1}=p_{2}=\cdots=p_{m}=\frac{n}{m}$&lt;/li>
&lt;li>有优先级的随机包含($P^{priority}$): $p_{1} \geq p_{2} \geq \cdots \geq p_{m} \text { and } \frac{p_{1}}{f_{1}}=\frac{p_{2}}{f_{2}}=\cdots=\frac{p_{m}}{f_{m}}$&lt;/li>
&lt;li>Top n ($P^{top}$): $p_{1}=p_{2}=\cdots=p_{n}=1 \text { and } p_{n+1}=p_{n+2}=\cdots=p_{m}=0$&lt;/li>
&lt;/ol>
&lt;p>这里仅考虑矿工收益中的交易费用奖励。&lt;/p>
&lt;h5 id="收入困境">收入困境&lt;/h5>
&lt;h3 id="算法设计">算法设计&lt;/h3>
&lt;h2 id="silentdelivery-practical-timed-delivery-of-private-information-using-smart-contracts">《SilentDelivery: Practical Timed-delivery of Private Information using Smart Contracts》&lt;/h2></description></item><item><title>DAG区块链综述</title><link>https://chi-kai.github.io/post/dag%E5%8C%BA%E5%9D%97%E9%93%BE%E7%BB%BC%E8%BF%B0/</link><pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate><guid>https://chi-kai.github.io/post/dag%E5%8C%BA%E5%9D%97%E9%93%BE%E7%BB%BC%E8%BF%B0/</guid><description>&lt;h2 id="问题现状">问题现状&lt;/h2>
&lt;h4 id="区块链面临的问题">区块链面临的问题&lt;/h4>
&lt;p>区块链作为现在一个热门技术，越来越多的人涌入其中。传统的区块链由于其单链结构和共识算法的限制，存在[!!!]等问题。
之前有研究工作提出，一个区块链中区块链的去中心化，安全，和规模三个特新不能共存。&lt;/p>
&lt;h4 id="解决方案">解决方案&lt;/h4>
&lt;ul>
&lt;li>分片技术: 将一个交易分片来并行处理，但是很难达成共识，跨链技术通过在不同分片之间建立通道来解决这个问题。&lt;/li>
&lt;li>Layer2 Protocl:参与者能够通过私有通信而不是广播到整个网络来执行脱（主）链交易挑战是如何正确有效地保证链下和链上交易的有效性和一致性。&lt;/li>
&lt;li>辅助链技术: 通过增加辅助链来让更多的交易参与。&lt;/li>
&lt;li>混合结构&lt;/li>
&lt;li>混合共识算法&lt;/li>
&lt;li>修改硬解码参数&lt;/li>
&lt;/ul>
&lt;p>这些方案都受限于区块链的线性结构，因此结构上的改变成为一个新兴方案。&lt;/p>
&lt;h4 id="dag区块链的提出">DAG区块链的提出&lt;/h4>
&lt;p>单链结构使得同一时间多个节点竞争一个可用位置，这导致了认证缓慢，交易竞争和算力浪费。
为了能在同一时间提交更多交易，提出了基于DAG的区块链。&lt;/p>
&lt;h2 id="概览">概览&lt;/h2>
&lt;p>DAG 是指有向无环图，通常被当作一种基础数据结构应用于导航寻址，数据压缩等算法场景。
这个概念首次被Sompolinksky在GHOST中引入区块链，用来解决并发问题。改进版本被作为核心共识算法应用于以太坊中。之后，Lerner在DAGCoin中将粒度从块提升到交易，抛弃了打包和计算步骤大大提高了效率。IOTA和ByteBall 应用了无块的概念，发布了开源实现，至今引领市场。随后，一些工作又在DAG的基础上进行了改进。如Spectre,Hashgraph,Nano等。&lt;/p>
&lt;p>基于DAG的系统主要有利于需要高性能低消耗的分布式应用(DAPP)。直接应用底层的区块链可以享受到更好的特性，但是需要专业的开发技巧和昂贵的硬件设备。使用一些官方的组件是一种可替代的方案，如IOTA,MAM,Qubic。目前可以考虑应用的领域有: 物联网，数据管理，车载应用，智能家具等。&lt;/p>
&lt;h2 id="建模">建模&lt;/h2>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7ytqxs2xdj30td0kdq8u.jpg" alt="DAG定义.png">&lt;/p>
&lt;p>一个有环无向图由点集和边集组成。点集的每个元素可以是一个交易，一个块，或者协议中的一个事件。边集的元素是一个元组，代表两点之间的关系。&lt;/p>
&lt;p>&lt;strong>关键参数&lt;/strong> 因为现在模型缺乏具体的实现，使用定性的参数来描述系统的基本技术。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>出度入度&lt;/strong>: 描述每个单元连接数目。 出度是指从节点指出的边，即节点的前任。入度是指指向节点的边，即节点的继承者。&lt;/li>
&lt;li>&lt;strong>交易模型&lt;/strong>：描述如何完成一笔交易。UXTO 代表一种无损耗的输出，交易时原子的，不可分割。每个操作必须通过这些交易完成。Account model 维持一种平衡状态。&lt;/li>
&lt;li>&lt;strong>可信度&lt;/strong>: 一个累加的数字展示一个单元被子块直接或者间接认证的程度。也反映下一轮被选择的概率。&lt;/li>
&lt;li>&lt;strong>认证&lt;/strong>: 一些独特的参数被用于在网络中认证单元。&lt;/li>
&lt;/ul>
&lt;h4 id="分类">分类&lt;/h4>
&lt;p>&lt;strong>节点表现形式&lt;/strong>&lt;/p>
&lt;p>这个间接显示一个系统结构，是交易，事件或者区块。我们定义两种类型: $1^{od}$ 和 $2^{od} $。 前者表示请求到达时会被即刻处理，不需要等待来自节点的更多请求。这种形式包括区块和触发事件。 后者表示请求需要更多操作，多数情况下这个请求需要被预先计算或打包，然后被散播。这种形式包括区块和事件。&lt;/p>
&lt;p>节点形式表示系统结构，同时也决定账本模型，表示交易如何在DAG中生成。有两种交易模型: UXTO-based model 和 account-based model。第一个意味着所有操作都必须通过原子事务来实现。用户可以通过跟踪以前的交易历史来计算余额。对于第二个，每个用户都拥有一个帐户，并且交易被配置为其结构中的字段之一。用户直接在他们的账户中计算余额。&lt;/p>
&lt;p>&lt;strong>网络技术&lt;/strong>&lt;/p>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7yywv7qowj31gt0hiq76.jpg" alt="三种类型.png">&lt;/p>
&lt;p>分为三种 &lt;strong>发散&lt;/strong>,&lt;strong>并行&lt;/strong>,&lt;strong>收敛&lt;/strong>。发散表示单元在不确定的方向稀疏的传播。并行表示在多个链的单元被一组节点维护。收敛表示单元按照一个确定的趋势收敛到一个确定的序列。&lt;/p>
&lt;p>按照上述标准分类如下:
&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7z2qpoyepj31kp0hywlh.jpg" alt="分类.png">&lt;/p>
&lt;h2 id="共识算法">共识算法&lt;/h2>
&lt;p>这里讨论共识算法的几个方面。&lt;/p>
&lt;p>&lt;strong>开放程度&lt;/strong>: 表明一个任意节点是否无限制运行共识算法。&lt;/p>
&lt;p>&lt;strong>成员选择&lt;/strong>: 选择节点成为出块节点的规则。&lt;/p>
&lt;p>&lt;strong>单元分配&lt;/strong>: 共识算法的准备。&lt;/p>
&lt;p>&lt;strong>单元定位&lt;/strong>: 确定一个单元在网络中的位置。&lt;/p>
&lt;p>&lt;strong>扩展规则&lt;/strong>: 如何扩展图或者链和解除联系。&lt;/p>
&lt;p>&lt;strong>冲突解决&lt;/strong>: 表示一系列可以确定冲突单元优先级的参数。&lt;/p>
&lt;p>&lt;strong>特别技术&lt;/strong>: 与其他系统不同的技术。&lt;/p>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7z3ukvzmpj31u11yfnpd.jpg" alt="共识分类.png">&lt;/p>
&lt;h4 id="第一类">第一类&lt;/h4>
&lt;p>&lt;strong>blockless ane natural expanding graph&lt;/strong>&lt;/p>
&lt;h5 id="iota">IOTA&lt;/h5>
&lt;p>无限制网络，使用UTXO数据模型，通过交易建立系统。IOTA把节点的事务称为tangle。一个待确认的tip需要先确认前面的两个tip，参与者也共同维护系统安全。但是如果恶意tips被持续生成，可能造成整个图向多个方向发散。所以tip选择算法是必不可少的，有三种机制提供: &lt;strong>一致随机，未加权随机和加权随机移动&lt;/strong>。最先进的是加权随机移动算法，是马尔可夫链蒙特卡罗 (MCMC) 算法的应用。有一些修改tip选择算法的变体，如GIOTA,EIOTA。&lt;/p>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h81275b065j30ha0amwgd.jpg" alt="IOTA.png">&lt;/p>
&lt;h5 id="graphchain">Graphchain:&lt;/h5>
&lt;p>无限制网络。&lt;/p>
&lt;p>IOAT去除了激励机制，而Graphchain又重新引入。每个交易必须认证足够多的节点来获得激励。&lt;/p>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h812l3mj9tj30os0cujsm.jpg" alt="图片.png">&lt;/p>
&lt;h5 id="avalancheq">Avalancheq&lt;/h5>
&lt;p>一个无限制,新共识机制的网络。&lt;/p>
&lt;p>共识机制不同于拜占庭和中本聪共识。是一种叫做&lt;strong>Slush&lt;/strong>的协议，从gossip算法和流行病网络中获得灵感的CFT容忍协议。&lt;/p>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h812t17em1j30rm0hw0vo.jpg" alt="图片.png">&lt;/p>
&lt;h4 id="第二类">第二类&lt;/h4>
&lt;p>&lt;strong>based on blocks,natural expanding graph&lt;/strong>&lt;/p>
&lt;h5 id="spectre">Spectre&lt;/h5>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/17/J2PbKE7sRvNtzuW.png" alt="">&lt;/p>
&lt;p>一种无限制网络。关键技术是基于块的优先级的递归加权投票算法，&lt;/p>
&lt;h5 id="phantom">Phantom&lt;/h5>
&lt;h4 id="总结">总结&lt;/h4>
&lt;p>从上面提到的区块链系统提取出常用的技术:&lt;/p>
&lt;ol>
&lt;li>Cross-referencing(交叉引用)。一个块可以引用多个区块，也可以被多个区块引用。交叉引用可以提高吞吐量，扩大规模，降低认证时间。&lt;/li>
&lt;li>Trusted authority。一个权威中心来做最后的决定，可以减少确认时间，但是会减弱去中心化特性。&lt;/li>
&lt;li>Pairwise vote(成对投票)。2 对 1 的投票选择，而不是正常投票算法中的 n 对 1。&lt;/li>
&lt;li>Transaction sharding(事务分片)。将交易分配到不同的链来阻止排序过程中可能的复制和冲突。&lt;/li>
&lt;li>PoW 机制。用作一个反恶意节点的工具，对于子序列的PoW是预先计算的，可以保证交易瞬间完成。&lt;/li>
&lt;/ol>
&lt;p>对常用的共识机制分析:&lt;/p>
&lt;ol>
&lt;li>Tip selection algorithm。一个新的交易如何选择之前的交易进行确认。增加了吞吐量和规模，一定程度上降低了安全性和一致性。&lt;/li>
&lt;li>Recursive algorithm。递归调用一个函数直到得到一个稳定值。这个算法被共识机制采用来使得无序的块聚合成一个有序的链，使系统可以在一个确定的方向扩展。&lt;/li>
&lt;li>BFT-style consensus。分为三种
&lt;ul>
&lt;li>传统BFT。需要根据资源确定(PoW，PoS)一个commitee,commitee成员来执行共识操作。&lt;/li>
&lt;li>async-BA/leaderless BFT: 每个链都可以广播块和投票，当一个块得到足够的票数就可以提交，但是由于这个提交和确认是异步的，所以一个全局的线性排序很难达到。&lt;/li>
&lt;li>前面两种的整合。经典的拜占庭容错协议首先应用于各个独立的区域，上层协议采用async-BA实现跨区域的最终共识。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Nakamoto consensus and its variants （中本聪共识和它的变体）。现存最流行的方法。传统的NC选择最长的链，变体NC选择权重最大的链，多用于形成主链。&lt;/li>
&lt;li>Sorting algorithm。按照总体的线性顺序来排序，对于确保全局一致性是必不可少的。根据一些参数来确定优先级。&lt;/li>
&lt;/ol>
&lt;h2 id="特性分析">特性分析&lt;/h2>
&lt;h3 id="ba和nc特性">BA和NC特性&lt;/h3>
&lt;p>拜占庭共识和中本聪共识是最流行的两种共识协议。&lt;/p>
&lt;h4 id="拜占庭共识">拜占庭共识&lt;/h4>
&lt;p>在存在恶意节点的情况下可以达成的共识。有三个特性:&lt;/p>
&lt;ul>
&lt;li>argeement:&lt;/li>
&lt;li>validity:&lt;/li>
&lt;li>termination:&lt;/li>
&lt;/ul>
&lt;h4 id="中本聪共识">中本聪共识&lt;/h4>
&lt;p>允许所有节点可以参与共识通过PoW,PoS等方式。有两个关键特性:&lt;/p>
&lt;ul>
&lt;li>persistence:&lt;/li>
&lt;li>liveness:&lt;/li>
&lt;/ul>
&lt;h2 id="安全分析">安全分析&lt;/h2>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/17/suHCLTGvFKi1bjc.png" alt="">&lt;/p>
&lt;h3 id="parasite-chain-attack">Parasite Chain Attack&lt;/h3>
&lt;p>尝试用预先准备好的子链来替换正确的子链。&lt;/p>
&lt;p>首先攻击者参照主链来构造一个有很高可信度的子链。然后分别发送一对冲突的交易到主链和构造的私链，接下来要确保子链得到有竞争力的可信度。这时，这个冲突交易可能已经在主链上确认，攻击者再发布他的子链，这样很可能使正确的主链无效然后一个coin可能被使用两次。&lt;/p>
&lt;p>这种攻击需要攻击者有充足的算力来生成区块，以没有强力领导者的协议为目标。&lt;/p>
&lt;h3 id="balance-attack--liveness-attack">Balance attack / liveness attack&lt;/h3>
&lt;p>保持多个子图平衡增长来获取收益，攻击者在一个子图发布交易后，又在另一个子图发布交易，动态维持几个子图的平衡来获取收益。&lt;/p>
&lt;p>需要一个很大算力，主要攻击基于POW的协议。&lt;/p>
&lt;h3 id="splitting-attack">Splitting attack&lt;/h3>
&lt;p>类似平衡攻击，攻击者找到两个相近的分支或者子图来发送冲突交易获取利润。&lt;/p>
&lt;p>攻击者需要有强大的算力，主要攻击没有强力中心的系统。&lt;/p>
&lt;h3 id="large--weight-attack">Large Weight Attack&lt;/h3>
&lt;h3 id="censorship-attack">Censorship Attack&lt;/h3>
&lt;h3 id="replay-attack">Replay Attack&lt;/h3>
&lt;h3 id="sybi-attack">Sybi Attack&lt;/h3>
&lt;h2 id="heading">&lt;/h2></description></item><item><title>联邦学习论文阅读</title><link>https://chi-kai.github.io/post/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link><pubDate>Sun, 06 Nov 2022 00:00:00 +0000</pubDate><guid>https://chi-kai.github.io/post/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</guid><description>&lt;h2 id="towards-on-device-federated-learning-a-direct-acyclic-graph-based-blockchain-approach">《Towards On-Device Federated Learning: A Direct Acyclic Graph-based Blockchain Approach》&lt;/h2>
&lt;h3 id="目标">目标&lt;/h3>
&lt;p>为了解决联邦学习中的设备异步和异常检测问题，同时避免由区块链导致的资源浪费&lt;/p>
&lt;ul>
&lt;li>
&lt;p>设备异步。传统的中心化和同步FL(Google FL),一个节点必须等待其他节点完成任务才能一起进入下一轮训练，一个崩溃的节点可能阻塞整个系统。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>异常检测。一个节点的数据集和操作对其他节点是不可见的。一些恶意节点可能会破坏整个系统的准确度和降低效率。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="主要贡献">主要贡献&lt;/h3>
&lt;p>提出了第一个基于DAG的FL异步框架来解决设备异步和异常节点检测问题。&lt;/p>
&lt;h3 id="dag-fl-模型">DAG-FL 模型&lt;/h3>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7vnbi5q76j30ru0n1tcw.jpg" alt="DAG-FL结构.png">&lt;/p>
&lt;p>“This feature promises that a node in DAG-FL can immediately participate in an iteration of FL whenever it is in idle state. When the node completes an iteration of FL and gets a new trained local model, the new local model can be published on its local DAG as a transaction immediately, and latter the new published transaction would be seen by all other nodes.” (&lt;a href="zotero://select/library/items/MG76RNTD">Cao 等。, p. 4&lt;/a>) (&lt;a href="zotero://open-pdf/library/items/BZ4CNUBL?page=4">pdf&lt;/a>) ”&lt;/p>
&lt;p>还是用本地的数据来训练模型，并没有和其他节点做聚合？&lt;/p>
&lt;p>“initial” (&lt;a href="zotero://select/library/items/MG76RNTD">Cao 等。, p. 5&lt;/a>) (&lt;a href="zotero://open-pdf/library/items/BZ4CNUBL?page=5">pdf&lt;/a>)&lt;/p>
&lt;h3 id="异步构架">异步构架&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>FL Layer:&lt;/p>
&lt;p>全局模型由存储在DAG中的本地模型使用FedAvg算法聚合产生，节点使用本地数据集进行训练。得到的新的模型被当作一个交易发布到DAG中。（每笔交易就是一个模型）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DAG Layer:&lt;/p>
&lt;p>每个节点维护一个本地DAG，其中每个交易包含下相应的认证信息，本地模型参数，和许可链接。本地DAG通过广播和无线网络更新，最终一个新的交易可以得到传播。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Application Layer:&lt;/p>
&lt;p>一个外部接口，通过智能合约发布任务。这个客户端可以观察整个FL过程的进展，从而控制整个FL的进行和停止。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>异步性分析：&lt;/p>
&lt;p>   在整个DAG-FL中没有central server,每个节点是通过本地已有的模型来构建新的全局模型。节点可以在合适的时间来进行FL迭代，获取的新的模型发布在本地DAG,随后可以被其他节点所见。节点之间的行为互不影响可以异步进行。&lt;/p>
&lt;h3 id="共识算法">共识算法&lt;/h3>
&lt;p>当一个节点完成一轮迭代，生成一个新的模型。他会从本地DAG选取几个tips(加入DAG但是没有被验证的block)来进行验证:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>验证使用RSA等算法加密的身份证书。可以避免恶意节点的女巫攻击。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用本地的测试集来计算模型的精确度。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>然后选取模型精确度最高的几个模型来构成新的全局模型。&lt;/p>
&lt;p>节点使用这个模型和本地数据集训练，得到的新模型通过一个新的交易发布到DAG中。&lt;/p>
&lt;p>随着DAG的持续扩展，一个交易的每次认证都意味着这个交易代表的模型被选择去构建一个全局模型，进而影响最终模型的生成。得到的认证越多，它在FL中的影响越大。反之，节点就会被孤立，在FL中影响越小。&lt;/p>
&lt;p>所以，最终DAG-FL训练的模型会向大多数节点期望的方向发展，少部分恶意节点会逐渐被孤立，影响降到最小化。&lt;/p>
&lt;h3 id="fl算法">FL算法&lt;/h3>
&lt;p>符号定义:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>D = {1,2,3,…,N $_D$ },代表整个设备集群。D $_i$是第i个节点。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>S $_i$是D $_i$的训练集，|S $_i$| = N $_i$,这里N $_i$是S $_i$的samples数量。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>D $_i$在本地创建一个仅自己可见的DAG为g $_i$，存储在其中的交易为w&lt;/p>
&lt;/li>
&lt;li>
&lt;p>时间t，在D $_i$训练得到的本地模型为w $_i$ $^t$&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>算法流程:&lt;/p>
&lt;ol>
&lt;li>D $_i$在t $_0$开始FL算法迭代，首先验证本地DAG的一些tips(验证他们的身份和用测试集验证准确度)&lt;/li>
&lt;li>将准确度较高的的k个tips使用FedAvg算法聚合成一个全局模型:
$$
\omega^{t_{0}}=\sum_{i=1}^{k} n_{i} \omega_{d_{i}}^{t_{i}}
$$
这里 n $_i$是表示模型重要性的权重因子，为了简化这里设置为1/k,表示同等重要。&lt;/li>
&lt;li>节点从数据集S $_i$中提取m个samples作为一个最小batch z$_i$ 来对得到的全局模型训练 $\beta$个epochs.&lt;/li>
&lt;li>得到一个新模型 $\omega &lt;em>{i}^{ t&lt;/em>{0}}$,将它发布到$g_{i}$上。&lt;/li>
&lt;/ol>
&lt;h3 id="dag-fl-操作">DAG-FL 操作&lt;/h3>
&lt;p>这里介绍框架中的两个重要算法。&lt;/p>
&lt;h4 id="dag-fl-controlling">DAG-FL Controlling&lt;/h4>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7voje2iexj30tp0r90zh.jpg" alt="DAG-FL Controlling.png">&lt;/p>
&lt;p>在应用层的外接客户端可以认为是一个权威组织，负责任务发布任务。通过智能合约执行DAG-FL 控制算法。过程如上图。&lt;/p>
&lt;h4 id="dag-fl-updating">DAG-FL Updating&lt;/h4>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7vro3iz6gj30tr0qu0ze.jpg" alt="DAG-FL Updating.png">&lt;/p>
&lt;p>节点在空闲时执行DAG-FL Updating 算法。&lt;/p>
&lt;ol>
&lt;li>节点随机从本地DAG选取staleness范围在可以接收的tip。&lt;/li>
&lt;li>节点先认证所选tips的身份，然后用自己的test数据集来计算所选tips的模型精确度。&lt;/li>
&lt;li>选择精确度高的k个tips，使用FedAvging算法得到一个全局模型。节点用本地数据来训练这个全局模型。&lt;/li>
&lt;li>一个新的交易被生成。包括身份信息，上一阶段训练得到的模型，和最k个tips的验证信息。&lt;/li>
&lt;/ol>
&lt;h3 id="未来工作">未来工作&lt;/h3>
&lt;ol>
&lt;li>在模型可用性上，使用一个小的test set可能对于一些特定场景不适合，考虑其他的异常检测方法。&lt;/li>
&lt;li>信用评估&lt;/li>
&lt;li>权重聚合。本文的模型使用的方法是同等权重系数的FedAvg,可以使用更好的方法来给高质量的模型更高的权重提高模型精度。&lt;/li>
&lt;/ol>
&lt;h2 id="implicit-model-specialization-through-dag-based-decentralized-federated-learning">《Implicit Model Specialization through DAG-based Decentralized Federated Learning》&lt;/h2>
&lt;h3 id="背景">背景&lt;/h3>
&lt;p>由于联邦学习数据的非独立同分布特性，所有节点训练一个模型太过宽泛，提出一种基于DAG区块链的联邦学习框架，所有节点利用本地数据和其他节点相似的数据训练自己的特例化模型，和全局的泛化模型结合来提高系统的性能。&lt;/p>
&lt;p>这篇论文是在联邦学习之前已经有的对本地数据特例化的研究基础上，引入DAG区块链。&lt;/p>
&lt;h3 id="模型">模型&lt;/h3>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/12/EWSmpuqlzK4TMAt.png" alt="">&lt;/p>
&lt;p>每个节点执行四个步骤，通过基础的随机移动算法选择DAG上的两个tips,将这个两个选择的模型参数平均，得到的模型在本地数据集上训练，如果最终得到的模型有提高就发布。&lt;/p>
&lt;h4 id="tips选择算法">tips选择算法&lt;/h4>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/12/clpHA9C21hkRoUV.png" alt="">
从区块链接的相反方向随机遍历。每个交易(区块)根据它的子图大小分配一个权重，通常会选择最高权重的区块，使得这个遍历方向收敛。
&lt;img src="https://s2.loli.net/2022/11/12/uJkGPclTq24VEDa.png" alt="">&lt;/p>
&lt;p>同时，对于每个节点有特定化的偏向处理，遍历的每一步，对于下一跳可以到达的潜在模型在本地数据集上进行评估。&lt;/p>
&lt;p>WEIGHTEDCHOICE 函数从这些模型中随机选择，并根据子节点对本地数据的精确度进行加权。（到底是按照权重还是随机选择？）&lt;/p>
&lt;p>这里的精确度计和权重计算：&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/12/NxPmWCyJBFhMAbv.png" alt="">&lt;/p>
&lt;p>遍历的随机性可以由 α 参数确定，其中值越大，权重之间的差异越大，因此随机性越小，确定性越高。另一方面，较小的 α 值会导致权重收敛，从而导致更多随机性。模型之间的预期精度差异取决于我们的方法所应用的机器学习问题，以及学习率、批量大小和局部时期等超参数。为了在模型之间的精度变化很小的情况下也能实现良好的特性化，即使在差异很大的情况下也能实现良好的泛化，将每个步骤中的精度分布 max(accuracies) - min(accuracies) 精度归一化 * 的一部分：&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/12/cHbGaDKXUvMLl6P.png" alt="">&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/12/7bDcLwGtZp2e1Co.png" alt="">&lt;/p>
&lt;h2 id="safa-a-semi-asynchronous-protocol-for-fast-federated-learning-with-low-overhead">《SAFA: A Semi-Asynchronous Protocol for Fast Federated Learning With Low Overhead》&lt;/h2>
&lt;h3 id="背景-1">背景&lt;/h3>
&lt;p>原有的FedAvg算法存在一些问题:&lt;/p>
&lt;ul>
&lt;li>同步开销大： 每轮迭代中央服务器需要传输全局模型给所有客户端，带宽达到一个峰值。&lt;/li>
&lt;li>客户端利用不足：随机选择的客户端使得许多可以参加训练的客户端闲置。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>这个论点不充分。FedAvg是在所有可用的客户端中随机选择一定比例，并不是完全随机的。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>进度浪费: 被选中的设备如果在完成本地训练之前失败，则之前的工作都会作废。&lt;/li>
&lt;li>每回合效率低: 在每轮结束进行聚合，FedAvg必须等待所有客户端完成。如果一些客户端故障，整个过程会等到超时结束。&lt;/li>
&lt;/ul>
&lt;h3 id="模型-1">模型&lt;/h3>
&lt;p>SAFA包括三部分: Lag-tolerant Model Distribution (&lt;strong>滞后容忍模型分布&lt;/strong>)，Compensatory
First-Come-First-Merge (CFCFM) client selection [&lt;strong>补偿性先到先合并 (CFCFM) 客户端选择&lt;/strong>],
discriminative aggregation (&lt;strong>判别聚合&lt;/strong>)&lt;/p>
&lt;p>下面SAFA的一个系统图:&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/13/R9dHQ6s1tjNDrWp.png" alt="">&lt;/p>
&lt;p>文中所用的参数表&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/13/wXgupKY9TJLVN3Z.png" alt="">&lt;/p>
&lt;h4 id="lag-tolerant-model-distribution">Lag-tolerant Model Distribution&lt;/h4>
&lt;p>整个模块关键的有两点:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>有选择的同步全局模型。&lt;/p>
&lt;p>不像FedAvg算法一样每轮每个参与节点都要同步模型，这是一个交流密集的过程，开销很大。SAFA模型只要求两种类型必须同步。&lt;strong>上一轮成功完成的节点(FedAvg中的正常节点)和被标记为过时的节点&lt;/strong>，这个过时节点是由于网络或者其他原因本地模型落后全局太多的客户端。这里有个滞后容忍参数 $\tau$，来调节这个滞后范围。&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/13/HYekTp8LqDa92Ic.png" alt="">&lt;/p>
&lt;p>这里t-1表示上一轮的最新模型, $\omega _{k}$代表第k个节点的本地模型，$\omega$ 代表全局模型。可以看到，在 $t- \tau$ 范围内本地节点的滞后是可以容忍的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>没有被选中的节点也可以参与迭代。&lt;/p>
&lt;p>没有被选中的节点也可以上传更新。这部分不会被直接合并，而是会通过一个bypass结构影响下一轮。
一个cache用来保存那些选中的节点上传的更新，没被选中的节点的更新保存在bypass中。bypass会在汇聚步骤完成后和cache合并,使得实际的有影响节点比率比参数C决定的更高。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="compensatory-first-come-first-merge-cfcfm-client-selection">Compensatory First-Come-First-Merge (CFCFM) client selection&lt;/h4>
&lt;p>代替必须等待所有选中节点上传更新，SAFA采用&lt;strong>先来先合并&lt;/strong>方法，只要上传的更新达到所需要的比率（是不是意味着可以上传的节点大于实际所需要的节点）就可以执行合并操作。&lt;/p>
&lt;p>给予那些参与较少的客户更高的优先级。在每一轮中，服务器都会维护一个错过上一轮训练的客户端的 id 列表，它们上传的更新会优先选择。&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/14/h6bZz4YPaOc87rf.png" alt="">&lt;/p>
&lt;h4 id="discriminative-aggregation">Discriminative Aggregation&lt;/h4>
&lt;p>聚合算法如下:&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/15/UlZErVnbgSC5KHG.png" alt="">&lt;/p>
&lt;p>对于选择的客户端，它们的更新将在合并到全局模型后保留在缓存中。对于未选择的客户端，更新不会在本轮生效，但会被缓存带入下一轮。对于崩溃的客户端，只有在它们没有被弃用的情况下，它们的模型才会保持不变。&lt;/p>
&lt;h4 id="算法流程">算法流程&lt;/h4>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/15/kxSZgVusbUM29hY.png" alt="">&lt;/p>
&lt;p>每轮开始时，服务器先检查客户端的模型，根据给定的超参数$\tau$和滞后容忍算法来分配模型。服务器收集上传的更新，错过上次更新的节点会被优先采集。等采集到的更新满足预先设置的标准后，执行三步合并，然后更新缓存状态。&lt;/p>
&lt;h2 id="iot-22a-blockchain-based-model-migration-approach-for-secure-and-sustainable-federated-learning-in-iot-systems">IOT ‘22《A Blockchain-based Model Migration Approach for Secure and Sustainable Federated Learning in IoT Systems》&lt;/h2>
&lt;h3 id="背景-2">背景&lt;/h3></description></item><item><title>Raft论文阅读</title><link>https://chi-kai.github.io/post/raft%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link><pubDate>Sun, 30 Oct 2022 00:00:00 +0000</pubDate><guid>https://chi-kai.github.io/post/raft%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</guid><description>&lt;h2 id="领导人选举">领导人选举&lt;/h2>
&lt;p>首先按照论文中最关键的figure 2补全节点和RPC结构。&lt;/p>
&lt;p>节点有三个状态: Leader,Candidate,Follower 和 两个计时器: 选举计时器，心跳计时器。&lt;/p>
&lt;p>&lt;strong>Follower&lt;/strong>: 有一个选举计时器，随机选举超时时间，每当选举超时，就转变为Candidate.&lt;/p>
&lt;p>&lt;strong>Candidate&lt;/strong>: 中间态，当Follower一端时间没有收到心跳，选举计时器到期，就会转变为Candidate,term加1，为自己投票并向其他节点发送投票请求，&lt;/p>
&lt;p>&lt;strong>Leader&lt;/strong>: 当一个Candidate获得半数以上的投票就会转变为Leader,最重要的节点，负责和客户端交互。需要定时向每个Follower发送心跳来维持权威。&lt;/p>
&lt;ol>
&lt;li>节点一开始状态都是Follower,Term为0。&lt;/li>
&lt;li>当一个选举计时器到期时，节点转变为Candidate，term加1，开始发送投票请求。这里有三种情况:
&lt;ul>
&lt;li>其他节点按照先来先到的原则投票，获得半数以上的投票可以胜出成为Leader.&lt;/li>
&lt;li>在选举过程中得到更高term的RPC，Candidate会转变为Follower.&lt;/li>
&lt;li>如果两个Candidate获得同样的票数，等选举计时器再次超时，会开始下一轮投票。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>选出Leader后，Leader马上广播心跳来维持权威。&lt;/li>
&lt;/ol>
&lt;p>代码遇到的问题:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>选举超时要真的随机时间，有的随机函数返回的是固定值，这里用时间做种子。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-golang" data-lang="golang">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75af00">r&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#75af00">rand&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">New&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#75af00">rand&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">NewSource&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#75af00">time&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">Now&lt;/span>&lt;span style="color:#111">().&lt;/span>&lt;span style="color:#75af00">UnixNano&lt;/span>&lt;span style="color:#111">()))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75af00">t&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#75af00">time&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">Duration&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#75af00">ElectionTime&lt;/span>&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#75af00">r&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">Intn&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#75af00">ElectionTime&lt;/span>&lt;span style="color:#111">))&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#75af00">time&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">Millisecond&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>由于网络原因，可能一些节点的回复不能及时收到。当收到一个超期的回复时，处理办法就是抛弃。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// 如果回复晚了，不是同一个term或者leader则抛弃
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// 处理心跳回复
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#00a8c8">if&lt;/span> &lt;span style="color:#75af00">rf&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">currentTerm&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#75af00">args&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">Term&lt;/span> &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#75af00">rf&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">state&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#75af00">StateLeader&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// 在本Term内的投票且state仍为Candidate，超时过期的丢弃
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// 处理投票回复
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#00a8c8">if&lt;/span> &lt;span style="color:#75af00">rf&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">state&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#75af00">StateCandidate&lt;/span> &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#75af00">rf&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">currentTerm&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#75af00">args&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">Term&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>当收到一个更高term的回复RPC,Candidate转变为Follower，term变为更高的term,投票变为null。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当收到一个更高的term的心跳时，状态转变为Follower,term变为更高的term,投票变为null。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>节点在两种情况拒绝投票，一是Candidate的term小于自己，二是自己在本term中已经投过票。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-golang" data-lang="golang">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">if&lt;/span> &lt;span style="color:#75af00">rf&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">currentTerm&lt;/span> &lt;span style="color:#111">&amp;gt;&lt;/span> &lt;span style="color:#75af00">args&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">Term&lt;/span> &lt;span style="color:#f92672">||&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#111">(&lt;/span>&lt;span style="color:#75af00">rf&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">currentTerm&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#75af00">args&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">Term&lt;/span> &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#75af00">rf&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">votedFor&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#75af00">rf&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">votedFor&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#75af00">args&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">CandidateId&lt;/span>&lt;span style="color:#111">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>锁的使用: 当一个数据有写有读，写和读必须加锁。如果一个数据只读不写，不用加锁。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="日志复制">日志复制&lt;/h2>
&lt;p>当选举结束后，leader开始为客户端提供服务。客户端发出的每一条请求会被交给leader处理。&lt;/p>
&lt;p>leader将每一条指令打包成一个entry &amp;lt;index,term,cmd&amp;gt;,将这个entry附加到日志中去，然后并行地发起 AppendEntries RPCs 给其他的服务器，让他们复制这条entry。&lt;/p>
&lt;p>当大部分服务器同意接收这个entry,leader将这个entry应用于状态机中，称为已提交，同时领导人的日志中之前的所有日志条目也都会被提交，包括由其他领导人创建的条目。然后将执行结果返回给客户端。&lt;/p>
&lt;p>为了维护日志的一致性，要保证日志匹配特性:&lt;/p>
&lt;ul>
&lt;li>如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。&lt;/li>
&lt;li>如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。&lt;/li>
&lt;/ul>
&lt;p>第一个特性由 “只有一个leader可以创建entry” 来保证。&lt;/p>
&lt;p>第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。它的步骤如下:&lt;/p>
&lt;p>**在发送附加日志 RPC 的时候，会带上上一条entry信息。**如果跟随者在它的日志中找不到包含相同index和term的条目，那么他就会拒绝接收新的日志条目。&lt;/p>
&lt;p>&lt;strong>找到最大共识点。&lt;/strong> 在被跟随者拒绝之后，leader就会减小 nextIndex 值并进行重试(发送再上一个entry),直到找到最大共识点，被follower接收。之后，leader会强制覆盖follower最大共识点后面所有日志。这样就保证follower与leader日志始终一致。&lt;/p>
&lt;blockquote>
&lt;p>leader为所有follower节点维持一个nextIndex，记录每个follower下一个日志的index。当一个leader刚刚当选的时候，初始化所有nextIndex为自己最后一条日志的Index加1。（假设所有follower与leader日志保持一致）。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>日志复制可以做一些优化。比如在正常复制时可以批量复制日志以减少系统调用的开销；在寻找共识点时可以只携带一条日志以减少不必要的流量传输。&lt;/p>
&lt;/blockquote>
&lt;h2 id="安全性">安全性&lt;/h2>
&lt;h3 id="选举限制">选举限制&lt;/h3>
&lt;p>leader 只能发送日志给follower，而不能从follower接收日志，所以选出的leader必须包含集群中所有已经提交的日志。&lt;/p>
&lt;p>在选举投票时，携带最新的日志信息，和follower相比较，看谁的日志最新。如果候选人更新，则获得投票。&lt;/p>
&lt;blockquote>
&lt;p>这里更新的定义是: 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。&lt;/p>
&lt;/blockquote>
&lt;h3 id="提交之前任期内的日志条目">提交之前任期内的日志条目&lt;/h3>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7oklyiaigj30ue0vaww7.jpg" alt="幽灵复现">&lt;/p>
&lt;p>在上图中，raft 为了避免出现一致性问题，要求 leader 绝不会提交过去的 term 的 entry （即使该 entry 已经被复制到了多数节点上）。leader 永远只提交当前 term 的 entry，过去的 entry 只会随着当前的 entry 被一并提交。（上图中的 c，term2 只会跟随 term4 被提交。）&lt;/p>
&lt;p>如果一个 candidate 能取得多数同意，说明它的日志已经是多数节点中最完备的， 那么也就可以认为该 candidate 已经包含了整个集群的所有 committed entries。&lt;/p>
&lt;p>因此 leader 当选后，应当立刻发起 AppendEntriesRPC 提交一个 no-op entry。注意，这是一个 Must，不是一个 Should，否则会有许多 corner case 存在问题。如:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>读请求：leader 此时的状态机可能并不是最新的，若服务读请求可能会违反线性一致性，即出现 safety 的问题；若不服务读请求则可能会有 liveness 的问题。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>配置变更：可能会导致数据丢失&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>实际上，leader 当选后提交一个 no-op entry 日志的做法就是Raft 算法解决 “幽灵复现” 问题的解法，&lt;a href="https://mp.weixin.qq.com/s/jzx05Q781ytMXrZ2wrm2Vg">相关博客&lt;/a>&lt;/p></description></item><item><title>联邦学习综述</title><link>https://chi-kai.github.io/post/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/</link><pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate><guid>https://chi-kai.github.io/post/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/</guid><description>&lt;h2 id="什么是联邦学习">什么是联邦学习&lt;/h2>
&lt;p>本质：联邦学习本质上是一种分布式机器学习技术，或机器学习框架。&lt;/p>
&lt;p>目标：联邦学习的目标是在保证数据隐私安全及合法合规的基础上，实现共同建模，提升AI模型的效果。&lt;/p>
&lt;h2 id="前置知识">前置知识:&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>IID：&lt;strong>独立同分布，表示一组随机变量的概率分布都相同，而且相互独立。例如掷色子。联邦学习背景下，数据集是非独立同分布的。&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>SGD: 梯度下降算法&lt;/p>
&lt;ul>
&lt;li>
&lt;p>绝大多数机器学习模型都有一个损失函数，来衡量预测值与实际值的差异。损失函数的值越小，模型的精确度就越高。通过使用梯度下降来调节参数，进而最小化损失函数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>损失函数里一般有两种参数，一种是控制输入信号量的权重(Weight, 简称 w ），另一种是调整函数与真实值距离的偏差（Bias，简称 b ）。我们所要做的工作，就是通过梯度下降方法，不断地调整权重 w 和偏差b，使得损失函数的值变得越来越小。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>通过计算梯度可以找到下降的方向，然后通过学习率a来控制下降的快慢。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-fallback" data-lang="fallback">&lt;span style="display:flex;">&lt;span>def train(X, y, W, B, alpha, max_iters):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    &amp;#39;‘’
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    选取所有的数据作为训练样本来执行梯度下降
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    X : 训练数据集
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    y : 训练数据集所对应的目标值
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    W : 权重向量
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    B ： 偏差变量
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    alpha ： 学习速率
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    max_iters : 梯度下降过程最大的迭代次数
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   &amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   dW = 0 # 初始化权重向量的梯度累加器
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   dB = 0 # 初始化偏差向量的梯度累加器
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   m = X.shape[0] # 训练数据的数量
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>  
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   # 开始梯度下降的迭代
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>   for i in range(max_iters):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       dW = 0 # 重新设置权重向量的梯度累加器
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       dB = 0 # 重新设置偏差向量的梯度累加器
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>      
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       # 对所有的训练数据进行遍历
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       for j in range(m):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>           # 1. 遍历所有的训练数据
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>           # 2. 计算每个训练数据的权重向量梯度w_grad和偏差向量梯度b_grad
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>           # 3. 把w_grad和b_grad的值分别累加到dW和dB两个累加器里
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>      
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       W = W - alpha * (dW / m) # 更新权重的值
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>       B = B - alpha * (dB / m) # 更新偏差的值
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    return W, B # 返回更新后的权重和偏差。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="优化过程">优化过程&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>固定总数 K 个客户端，每个客户端都有本地数据集。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每次选取分数 C （比例）个客户端&lt;/p>
&lt;/li>
&lt;li>
&lt;p>服务器将当前的全局算法发送给每个客户端。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个被选定的客户端执行本地计算，并将服务器更新。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="通信成本占主导">通信成本占主导&lt;/h2>
&lt;p>一般数据中心中，通讯花费占少数，计算花费占大头。但是在联邦优化中，通讯占主导地位&lt;/p>
&lt;ul>
&lt;li>
&lt;p>通常上传带宽被限制到1MB或者更低。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>客户端只有在&lt;strong>充电，插入电源，和有不限量WIFI&lt;/strong>的情况下才会参与到优化过程中来。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>希望每个客户每天只参加少量的更新回合&lt;/strong>。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>因为单个客户端的训练数据很小，而且当前智能手机等客户端的计算能力是足够强的，所以&lt;strong>通过使用额外的计算量来减少通信的次数&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>增加并行量&lt;/strong>。在每次通信过程中，使用更多客户端来更新。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>增加每个客户端的计算量&lt;/strong>。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="联邦平均算法">联邦平均算法&lt;/h2>
&lt;p>联邦背景下，对梯度下降算法的扩展。&lt;/p>
&lt;p>选取K个Client，Server将当前的参数传递给Client,Client根据本地数据集和参数来进行梯度下降。&lt;/p>
&lt;p>最后将训练后的参数返回给Server,Server将获得的所有参数加权处理后得到最终的参数。然后再进行下一轮计算。&lt;/p>
&lt;p>&lt;img src="http://tva1.sinaimg.cn/large/008upJWily1h7of7bwegjj30re0p00ym.jpg" alt="fedsvg.png">&lt;/p>
&lt;p>如图所示，当B $\rightarrow$ $\infty$，E $\rightarrow$ 1  表示本地数据全部参与训练，只训练一次，称为FedSGD。&lt;/p>
&lt;h2 id="分类">分类&lt;/h2>
&lt;p>我们把每个参与共同建模的企业称为参与方，根据多参与方之间数据分布的不同，把联邦学习分为三类：横向联邦学习、纵向联邦学习和联邦迁移学习。&lt;/p>
&lt;h3 id="横向联邦学习">横向联邦学习&lt;/h3>
&lt;p>横向联邦学习的本质是 &lt;strong>样本的联合&lt;/strong>，适用于参与者间业态相同但触达客户不同，即特征重叠多，用户重叠少时的场景，比如不同地区的银行间，他们的业务相似（特征相似），但用户不同（样本不同）&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/29/DbjBYyxuRgdhQrF.png" alt="">&lt;/p>
&lt;h4 id="学习过程">学习过程:&lt;/h4>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/29/Myue2zbxD9JIs1Z.png" alt="">&lt;/p>
&lt;ul>
&lt;li>参与方各自从服务器A下载最新模型&lt;/li>
&lt;li>每个参与方利用本地数据训练模型，加密梯度上传给服务器A，服务器A聚合各用户的梯度更新模型参数；&lt;/li>
&lt;li>服务器A返回更新后的模型给各参与方；&lt;/li>
&lt;li>各参与方更新各自模型。&lt;/li>
&lt;/ul>
&lt;h3 id="纵向联邦学习">纵向联邦学习&lt;/h3>
&lt;p>纵向联邦学习的本质是 &lt;strong>特征的联合&lt;/strong>，适用于用户重叠多，特征重叠少的场景，比如同一地区的商超和银行，他们触达的用户都为该地区的居民（样本相同），但业务不同（特征不同）。&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/29/9RFpChvgXyAMSBY.png" alt="">&lt;/p>
&lt;h4 id="学习过程-1">学习过程&lt;/h4>
&lt;p>纵向联邦学习的本质是交叉用户在不同业态下的特征联合，比如商超A和银行B，在传统的机器学习建模过程中，需要将两部分数据集中到一个数据中心，然后再将每个用户的特征join成一条数据用来训练模型，所以就需要双方有用户交集（基于join结果建模），并有一方存在label。其学习步骤如上图所示，分为两大步：&lt;/p>
&lt;p>&lt;img src="https://s2.loli.net/2022/11/29/tOUj1Jx6MyslKL7.png" alt="">&lt;/p>
&lt;p>第一步：加密样本对齐。是在系统级做这件事，因此在企业感知层面不会暴露非交叉用户。&lt;/p>
&lt;p>第二步：对齐样本进行模型加密训练：&lt;/p>
&lt;ul>
&lt;li>由第三方C向A和B发送公钥，用来加密需要传输的数据；&lt;/li>
&lt;li>A和B分别计算和自己相关的特征中间结果，并加密交互，用来求得各自梯度和损失；&lt;/li>
&lt;li>A和B分别计算各自加密后的梯度并添加掩码发送给C，同时B计算加密后的损失发送给C；&lt;/li>
&lt;li>C解密梯度和损失后回传给A和B，A、B去除掩码并更新模型。&lt;/li>
&lt;/ul>
&lt;h3 id="联邦迁移学习">联邦迁移学习&lt;/h3>
&lt;p>当参与者间特征和样本重叠都很少时可以考虑使用联邦迁移学习，如不同地区的银行和商超间的联合。主要适用于以深度神经网络为基模型的场景。&lt;/p>
&lt;p>迁移学习，是指利用数据、任务、或模型之间的相似性，将在源领域学习过的模型，应用于 目标领域的一种学习过程。&lt;/p></description></item></channel></rss>